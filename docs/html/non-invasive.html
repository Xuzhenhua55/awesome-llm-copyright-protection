<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>
      Non-invasive Fingerprinting - LLM Copyright Protection Research
    </title>
    <link rel="stylesheet" href="../assets/style.css" />
    <link rel="stylesheet" href="../assets/nav.css" />
    <link rel="stylesheet" href="../assets/footer.css" />
    <link rel="stylesheet" href="../assets/paper-ref.css" />
    <link rel="stylesheet" href="../assets/layout.css" />
    <style>
      .intro-flex-container {
        display: flex;
        gap: 2rem;
        align-items: flex-start;
        margin-top: 1.5rem;
      }
      .intro-text-content {
        flex: 1;
        min-width: 0;
      }
      .intro-image-content {
        flex: 0 0 300px;
      }
      @media (max-width: 768px) {
        .intro-flex-container {
          flex-direction: column;
          gap: 1.5rem;
        }
        .intro-image-content {
          flex: none;
          align-self: center;
          max-width: 250px;
        }
      }
    </style>
    <script>
      // Preload navigation content
      const cachedNav = localStorage.getItem("navContent");
      if (cachedNav) {
        document.addEventListener("DOMContentLoaded", () => {
          const navPlaceholder = document.getElementById("nav-placeholder");
          if (navPlaceholder) {
            navPlaceholder.innerHTML = cachedNav;
          }
        });
      }
    </script>
  </head>
  <body>
    <div id="nav-placeholder">
      <script>
        // Try to populate navigation immediately if available
        const navContent = localStorage.getItem("navContent");
        if (navContent) {
          document.write(navContent);
        }
      </script>
    </div>

    <div class="main-content">
      <div class="header-section">
        <h1>Non-invasive Fingerprinting</h1>
        <div class="intro-flex-container">
          <div class="intro-text-content">
            <p class="intro-text" style="margin-bottom: 1rem">
              Non-invasive fingerprinting methods leverage the inherent
              properties of language models without requiring modifications to
              their architecture or training process. Specifically, these
              methods can extract fingerprints from the model's weight space and
              feature space. Additionally, a novel approach based on prompt
              optimization strategies attempts to utilize the model's decision
              boundary characteristics as distinctive fingerprints.
            </p>
            <p
              style="
                color: #666;
                font-style: italic;
                font-size: 0.95em;
                line-height: 1.4;
                margin-top: 1rem;
              "
            >
              <strong>Figure:</strong> Overview of intrinsic (non-invasive)
              fingerprinting methods, showing parameter-based,
              representation-based, semantic feature extraction, and adversarial
              example-based approaches.
            </p>
          </div>
          <div class="intro-image-content">
            <img
              src="../assets/figures/intrinsic_fingerprint.png"
              alt="Intrinsic Fingerprinting Process"
              style="
                width: 100%;
                height: auto;
                border-radius: 8px;
                box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
              "
            />
          </div>
        </div>
      </div>

      <div class="section-card">
        <h2>Parameter Space</h2>
        <p>
          Methods that analyze the weight space of language models to identify
          unique patterns and characteristics.
        </p>
        <div id="weightSpace-papers" class="paper-list"></div>
      </div>

      <div class="section-card">
        <h2>Representation Features</h2>
        <p>
          Methods that analyze the internal representations of LLMs, including
          activation patterns, hidden states, and output logits, which are
          derived from the data, strategies, and frameworks used during the
          training process. These representations serve as intrinsic features
          for model identification, capturing the unique characteristics of how
          different models process and transform information. The output logits,
          representing the model's prediction probabilities, also reflect the
          model's learned patterns and decision boundaries, making them valuable
          for fingerprinting purposes.
        </p>
        <div id="representationFeatures-papers" class="paper-list"></div>
      </div>

      <div class="section-card">
        <h2>Semantic Feature Extraction</h2>
        <p>
          This category of methods conducts statistical analysis on the content
          generated by different models, exploiting the linguistic patterns and
          semantic preferences exhibited by various LLMs as their unique
          fingerprints.
        </p>
        <div id="semanticFeatures-papers" class="paper-list"></div>
      </div>

      <div class="section-card">
        <h2>Adversarial Example-Based</h2>
        <p>
          The fundamental process of prompt optimization-based fingerprinting
          can be understood as follows: given an original input and a predefined
          response, the method optimizes the prompt to obtain a final version
          that, when input to the model, produces the predefined response. Since
          this optimization process is tightly coupled with the model's weights,
          the resulting optimized prompt is effective only for the target model
          and ineffective for other unrelated models, thus serving as a stable
          fingerprint feature.
        </p>
        <div id="promptOptimization-papers" class="paper-list"></div>
      </div>
    </div>

    <div id="footer-placeholder"></div>

    <script src="../assets/nav.js"></script>
    <script src="../assets/footer.js"></script>
    <script src="../assets/paper-ref.js"></script>
    <script>
      // Add paper references
      const papers = {
        weightSpace: [
          {
            title: "HuRef: HUman-REadable Fingerprint for Large Language Models",
            link: "https://arxiv.org/abs/2312.04828",
            venue: "arXiv 2023",
            bibtex: `@article{zeng2023huref,
  title={HuRef: HUman-REadable Fingerprint for Large Language Models},
  author={Zeng, Boyi and Zhou, Chenghu and Wang, Xinbing and Lin, Zhouhan},
  journal={arXiv preprint arXiv:2312.04828},
  year={2023}
}`
          },
          {
            title: "Reef: Representation encoding fingerprints for large language models",
            link: "https://arxiv.org/abs/2410.14273",
            venue: "arXiv 2024",
            bibtex: `@article{zhang2024reef,
  title={Reef: Representation encoding fingerprints for large language models},
  author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2410.14273},
  year={2024}
}`
          },
          {
            title: "Intrinsic Fingerprint of LLMs: Continue Training is NOT All You Need to Steal A Model!",
            link: "https://arxiv.org/abs/2507.03014",
            venue: "arXiv 2025",
            bibtex: `@article{yoon2025intrinsic,
  title={Intrinsic Fingerprint of LLMs: Continue Training is NOT All You Need to Steal A Model!},
  author={Yoon, Do-hyeon and Chun, Minsoo and Allen, Thomas and M\\\"uller, Hans and Wang, Min and Sharma, Rajesh},
  journal={arXiv preprint arXiv:2507.03014},
  year={2025}
}`
          },
        ],
        representationFeatures: [
          {
            title: "Copy, right? a testing framework for copyright protection of deep learning models",
            link: "https://ieeexplore.ieee.org/document/9833777",
            venue: "IEEE S&P 2022",
            bibtex: `@inproceedings{chen2022copy,
  title={Copy, right? a testing framework for copyright protection of deep learning models},
  author={Chen, Jialuo and Wang, Jingyi and Peng, Tinglan and Sun, Youcheng and Cheng, Peng and Ji, Shouling and Ma, Xingjun and Li, Bo and Song, Dawn},
  booktitle={2022 IEEE symposium on security and privacy (SP)},
  pages={824--841},
  year={2022},
  organization={IEEE}
}`
          },
          {
            title: "zkllm: Zero knowledge proofs for large language models",
            link: "https://dl.acm.org/doi/abs/10.1145/3605769.3644833",
            venue: "ACM CCS 2024",
            bibtex: `@inproceedings{sun2024zkllm,
  title={zkllm: Zero knowledge proofs for large language models},
  author={Sun, Haochen and Li, Jason and Zhang, Hongyang},
  booktitle={Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
  pages={4405--4419},
  year={2024}
}`
          },
          {
            title: "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
            link: "https://arxiv.org/abs/2506.01631",
            venue: "arXiv 2025",
            bibtex: `@article{wu2025gradient,
  title={Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification},
  author={Wu, Zehao and Zhao, Yanjie and Wang, Haoyu},
  journal={arXiv preprint arXiv:2506.01631},
  year={2025}
}`
          },
          {
            title: "Riemannian-Geometric Fingerprints of Generative Models",
            link: "https://arxiv.org/abs/2506.22802",
            venue: "arXiv 2025",
            bibtex: `@article{song2025riemannian,
  title={Riemannian-Geometric Fingerprints of Generative Models},
  author={Song, Hae Jin and Itti, Laurent},
  journal={arXiv preprint arXiv:2506.22802},
  year={2025}
}`
          },
          {
            title: "Llms have rhythm: Fingerprinting large language models using inter-token times and network traffic analysis",
            link: "https://ieeexplore.ieee.org/document/10839077/",
            venue: "IEEE Comm. Soc. 2025",
            bibtex: `@article{alhazbi2025llms,
  title={Llms have rhythm: Fingerprinting large language models using inter-token times and network traffic analysis},
  author={Alhazbi, Saeif and Hussain, Ahmed and Oligeri, Gabriele and Papadimitratos, Panos},
  journal={IEEE Open Journal of the Communications Society},
  year={2025},
  publisher={IEEE}
}`
          },
        ],
        semanticFeatures: [
          {
            title: "A Fingerprint for Large Language Models",
            link: "https://arxiv.org/abs/2407.10886",
            venue: "arXiv 2024",
            bibtex: `@article{liu2024fingerprint,
    title={A Fingerprint for Large Language Models},
    author={Liu, Dongrui and Zhang, Jie and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
    journal={arXiv preprint arXiv:2407.10886},
    year={2024}
}`
          },
          {
            title: "Invisible Traces: Using Hybrid Fingerprinting to identify underlying LLMs in GenAI Apps",
            link: "https://arxiv.org/abs/2501.18712",
            venue: "arXiv 2025",
            bibtex: `@misc{bhardwaj2025invisibletracesusinghybrid,
      title={Invisible Traces: Using Hybrid Fingerprinting to identify underlying LLMs in GenAI Apps},
      author={Devansh Bhardwaj and Naman Mishra},
      year={2025},
      eprint={2501.18712},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.18712},
}`
          },
          {
            title: "Detecting Stylistic Fingerprints of Large Language Models",
            link: "https://arxiv.org/abs/2503.01659",
            venue: "arXiv 2025",
            bibtex: `@article{bitton2025detecting,
  title={Detecting Stylistic Fingerprints of Large Language Models},
  author={Bitton, Yehonatan and Bitton, Elad and Nisan, Shai},
  journal={arXiv preprint arXiv:2503.01659},
  year={2025}
}`
          },
          {
            title: "Watermarking language models through language models",
            link: "https://arxiv.org/abs/2411.05091",
            venue: "arXiv 2024",
            bibtex: `@article{dasgupta2024watermarking,
  title={Watermarking language models through language models},
  author={Dasgupta, Agnibh and Tanvir, Abdullah and Zhong, Xin},
  journal={arXiv preprint arXiv:2411.05091},
  year={2024}
}`
          },
        ],
        promptOptimization: [
          {
            title: "FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint",
            link: "https://arxiv.org/abs/2501.15509",
            venue: "arXiv 2025",
            bibtex: `@misc{shao2025fitprintfalseclaimresistantmodelownership,
      title={FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint},
      author={Shuo Shao and Haozhe Zhu and Yiming Li and Hongwei Yao and Tianwei Zhang and Zhan Qin},
      year={2025},
      eprint={2501.15509},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2501.15509},
}`
          },
          {
            title:
              "ProFLingo: A Fingerprinting-based Intellectual Property Protection Scheme for Large Language Models",
            link: "https://ieeexplore.ieee.org/abstract/document/10735575/",
            venue: "CNS 2024",
            code: "https://github.com/hengvt/ProFLingo",
            bibtex: `@inproceedings{jin2024proflingo,
                        title={Proflingo: A fingerprinting-based intellectual property protection scheme for large language models},
                        author={Jin, Heng and Zhang, Chaoyu and Shi, Shanghao and Lou, Wenjing and Hou, Y Thomas},
                        booktitle={2024 IEEE Conference on Communications and Network Security (CNS)},
                        pages={1--9},
                        year={2024},
                        organization={IEEE}
                    }`,
          },
          {
            title:
              "RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models",
            link: "https://arxiv.org/abs/2505.06304",
            venue: "arXiv 2025",
            bibtex: `@article{zhang2025rap,
                        title={RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models},
                        author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
                        journal={arXiv preprint arXiv:2505.06304},
                        year={2025}
                    }`,
          },
          {
            title: "RoFL: Robust Fingerprinting of Language Models",
            link: "https://arxiv.org/abs/2505.12682",
            venue: "arXiv 2025",
            code: "https://github.com/yunyuntsa/RoFL",
            bibtex: `@article{tsai2025rofl,
                        title={RoFL: Robust Fingerprinting of Language Models},
                        author={Tsai, Yun-Yun and Guo, Chuan and Yang, Junfeng and van der Maaten, Laurens},
                        journal={arXiv preprint arXiv:2505.12682},
                        year={2025}
                    }`,
          },
        ],
      };

      document.addEventListener("DOMContentLoaded", () => {
        // Add papers to their respective containers
        Object.entries(papers).forEach(([category, paperList]) => {
          const container = document.getElementById(`${category}-papers`);
          if (container && paperList.length > 0) {
            paperList.forEach((paper) => {
              container.appendChild(createPaperReference(paper));
            });
          }
        });
      });
    </script>
  </body>
</html>
