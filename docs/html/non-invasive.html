<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
     <title>
       Non-invasive Fingerprinting - LLM Copyright Protection Research
     </title>
     <link rel="icon" type="image/svg+xml" href="../assets/logo.svg" />
     <link rel="stylesheet" href="../assets/style.css" />
    <link rel="stylesheet" href="../assets/nav.css" />
    <link rel="stylesheet" href="../assets/footer.css" />
    <link rel="stylesheet" href="../assets/paper-ref.css" />
    <link rel="stylesheet" href="../assets/layout.css" />
    <style>
      .intro-flex-container {
        display: flex;
        gap: 2rem;
        align-items: flex-start;
        margin-top: 1.5rem;
      }
      .intro-text-content {
        flex: 1;
        min-width: 0;
      }
      .intro-image-content {
        flex: 0 0 300px;
      }
      @media (max-width: 768px) {
        .intro-flex-container {
          flex-direction: column;
          gap: 1.5rem;
        }
        .intro-image-content {
          flex: none;
          align-self: center;
          max-width: 250px;
        }
      }
    </style>
    <script>
      // Preload navigation content
      const cachedNav = localStorage.getItem("navContent");
      if (cachedNav) {
        document.addEventListener("DOMContentLoaded", () => {
          const navPlaceholder = document.getElementById("nav-placeholder");
          if (navPlaceholder) {
            navPlaceholder.innerHTML = cachedNav;
          }
        });
      }
    </script>
  </head>
  <body>
    <div id="nav-placeholder">
      <script>
        // Try to populate navigation immediately if available
        const navContent = localStorage.getItem("navContent");
        if (navContent) {
          document.write(navContent);
        }
      </script>
    </div>

    <div class="main-content">
      <div class="header-section">
        <h1>Non-invasive Fingerprinting</h1>
        <div class="intro-flex-container">
          <div class="intro-text-content">
            <p class="intro-text" style="margin-bottom: 1rem">
              Non-invasive fingerprinting methods leverage the inherent
              properties of language models without requiring modifications to
              their architecture or training process. Specifically, these
              methods can extract fingerprints from the model's weight space and
              feature space. Additionally, a novel approach based on prompt
              optimization strategies attempts to utilize the model's decision
              boundary characteristics as distinctive fingerprints.
            </p>
            <p
              style="
                color: #666;
                font-style: italic;
                font-size: 0.95em;
                line-height: 1.4;
                margin-top: 1rem;
              "
            >
              <strong>Figure:</strong> Overview of intrinsic (non-invasive)
              fingerprinting methods, showing parameter-based,
              representation-based, semantic feature extraction, and adversarial
              example-based approaches.
            </p>
          </div>
          <div class="intro-image-content">
            <img
              src="../assets/figures/intrinsic_fingerprint.png"
              alt="Intrinsic Fingerprinting Process"
              style="
                width: 100%;
                height: auto;
                border-radius: 8px;
                box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
              "
            />
          </div>
        </div>
      </div>

      <div class="section-card">
        <h2>Parameter Space</h2>
        <p>
          Methods that analyze the weight space of language models to identify
          unique patterns and characteristics.
        </p>
        <div id="weightSpace-papers" class="paper-list"></div>
      </div>

      <div class="section-card">
        <h2>Representation Features</h2>
        <p>
          Methods that analyze the internal representations of LLMs, including
          activation patterns, hidden states, and output logits, which are
          derived from the data, strategies, and frameworks used during the
          training process. These representations serve as intrinsic features
          for model identification, capturing the unique characteristics of how
          different models process and transform information. The output logits,
          representing the model's prediction probabilities, also reflect the
          model's learned patterns and decision boundaries, making them valuable
          for fingerprinting purposes.
        </p>
        <div id="representationFeatures-papers" class="paper-list"></div>
      </div>

      <div class="section-card">
        <h2>Semantic Feature Extraction</h2>
        <p>
          This category of methods conducts statistical analysis on the content
          generated by different models, exploiting the linguistic patterns and
          semantic preferences exhibited by various LLMs as their unique
          fingerprints.
        </p>
        <div id="semanticFeatures-papers" class="paper-list"></div>
      </div>

      <div class="section-card">
        <h2>Adversarial Example-Based</h2>
        <p>
          The fundamental process of prompt optimization-based fingerprinting
          can be understood as follows: given an original input and a predefined
          response, the method optimizes the prompt to obtain a final version
          that, when input to the model, produces the predefined response. Since
          this optimization process is tightly coupled with the model's weights,
          the resulting optimized prompt is effective only for the target model
          and ineffective for other unrelated models, thus serving as a stable
          fingerprint feature.
        </p>
        <div id="promptOptimization-papers" class="paper-list"></div>
      </div>
    </div>

    <div id="footer-placeholder"></div>

    <script src="../assets/nav.js"></script>
    <script src="../assets/footer.js"></script>
    <script src="../assets/paper-ref.js"></script>
    <script>
      // Add paper references
      const papers = {
        weightSpace: [
           {
             title: "HuRef: HUman-REadable Fingerprint for Large Language Models",
             link: "https://arxiv.org/abs/2312.04828",
             venue: "arXiv 2023",
             bibtex: `@article{zeng2023huref,
   title={HuRef: HUman-REadable Fingerprint for Large Language Models},
   author={Zeng, Boyi and Zhou, Chenghu and Wang, Xinbing and Lin, Zhouhan},
   journal={arXiv preprint arXiv:2312.04828},
   year={2023}
 }`,
             surveyTag: "âœðŸ»"
           },
          {
            title: "Copy, Right? A Testing Framework for Copyright Protection of Deep Learning Models",
            link: "https://arxiv.org/abs/2112.05588",
            venue: "IEEE S&P 2022",
            bibtex: `@inproceedings{chen2022copy,
   title={Copy, Right? A Testing Framework for Copyright Protection of Deep Learning Models},
   author={Chen, Jialuo and Wang, Jingyi and Peng, Tinglan and Sun, Youcheng and Cheng, Peng and Ji, Shouling and Ma, Xingjun and Li, Bo and Song, Dawn},
   booktitle={Proceedings of the 2022 IEEE Symposium on Security and Privacy (SP)},
   pages={824--841},
   year={2022}
 }`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "Intrinsic Fingerprint of LLMs: Continue Training is NOT All You Need to Steal A Model!",
            link: "https://arxiv.org/abs/2507.03014",
            venue: "arXiv 2025",
            bibtex: `@article{yoon2025intrinsic,
   title={Intrinsic Fingerprint of LLMs: Continue Training is NOT All You Need to Steal A Model!},
   author={Yoon, Do-hyeon and Chun, Minsoo and Allen, Thomas and M\\\"uller, Hans and Wang, Min and Sharma, Rajesh},
   journal={arXiv preprint arXiv:2507.03014},
   year={2025}
 }`,
            surveyTag: "âœðŸ»"
          },
        ],
        representationFeatures: [
          {
            title: "Reef: Representation encoding fingerprints for large language models",
            link: "https://arxiv.org/abs/2410.14273",
            venue: "arXiv 2024",
            bibtex: `@article{zhang2024reef,
   title={Reef: Representation encoding fingerprints for large language models},
   author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
   journal={arXiv preprint arXiv:2410.14273},
   year={2024}
 }`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "Copy, Right? A Testing Framework for Copyright Protection of Deep Learning Models",
            link: "https://arxiv.org/abs/2112.05588",
            venue: "IEEE S&P 2022",
            bibtex: `@inproceedings{chen2022copy,
   title={Copy, Right? A Testing Framework for Copyright Protection of Deep Learning Models},
   author={Chen, Jialuo and Wang, Jingyi and Peng, Tinglan and Sun, Youcheng and Cheng, Peng and Ji, Shouling and Ma, Xingjun and Li, Bo and Song, Dawn},
   booktitle={Proceedings of the 2022 IEEE Symposium on Security and Privacy (SP)},
   pages={824--841},
   year={2022}
 }`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "zkLLM: Zero Knowledge Proofs for Large Language Models",
            link: "https://arxiv.org/abs/2404.16109",
            venue: "ACM CCS 2024",
            bibtex: `@article{sun2024zkllm,
  title={zkLLM: Zero Knowledge Proofs for Large Language Models},
  author={Sun, Haochen and Li, Jason and Zhang, Hongyang},
  journal={arXiv preprint arXiv:2404.16109},
  year={2024}
}`,
            surveyTag: "âœðŸ»",
          },
          {
            title: "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
            link: "https://arxiv.org/abs/2506.01631",
            venue: "arXiv 2025",
            bibtex: `@article{wu2025gradient,
   title={Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification},
   author={Wu, Zehao and Zhao, Yanjie and Wang, Haoyu},
   journal={arXiv preprint arXiv:2506.01631},
   year={2025}
 }`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "Riemannian-Geometric Fingerprints of Generative Models",
            link: "https://arxiv.org/abs/2506.22802",
            venue: "arXiv 2025",
            bibtex: `@article{song2025riemannian,
   title={Riemannian-Geometric Fingerprints of Generative Models},
   author={Song, Hae Jin and Itti, Laurent},
   journal={arXiv preprint arXiv:2506.22802},
   year={2025}
 }`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "LLMs Have Rhythm: Fingerprinting Large Language Models Using Inter-Token Times and Network Traffic Analysis",
            link: "https://arxiv.org/abs/2502.20589",
            venue: "arXiv 2025",
            bibtex: `@article{alhazbi2025llms,
   title={LLMs Have Rhythm: Fingerprinting Large Language Models Using Inter-Token Times and Network Traffic Analysis},
   author={Alhazbi, Saeif and Hussain, Ahmed Mohamed and Oligeri, Gabriele and Papadimitratos, Panos},
   journal={arXiv preprint arXiv:2502.20589},
   year={2025}
 }`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting",
            link: "https://arxiv.org/abs/2501.16029",
            venue: "arXiv preprint 2025",
            bibtex: `@article{liu2025fdllm,
  title={FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting},
  author={Liu, Han and Wang, Jinpeng and Zhou, Xin and Zhang, Hui and Xu, Shujian and Yang, Zhendong},
  journal={arXiv preprint arXiv:2501.16029},
  year={2025}
}`
          },
        ],
        semanticFeatures: [
          {
            title: "A Fingerprint for Large Language Models",
            link: "https://arxiv.org/abs/2407.01235",
            venue: "arXiv 2024",
            bibtex: `@misc{yang2024fingerprintlargelanguagemodels,
      title={A Fingerprint f
      or Large Language Models}, 
      author={Zhiguang Yang and Hanzhou Wu},
      year={2024},
      eprint={2407.01235},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2407.01235}, 
}`
          },
          {
            title: "LLMMap: Fingerprinting for Large Language Models",
            link: "https://arxiv.org/abs/2407.15847",
            venue: "arXiv 2024",
            bibtex: `@article{pasquini2024llmmap,
  title={LLMMap: Fingerprinting for Large Language Models},
  author={Pasquini, Dario and Kornaropoulos, Evgenios M and Ateniese, Giuseppe},
  journal={arXiv preprint arXiv:2407.15847},
  year={2024}
}`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection",
            link: "https://arxiv.org/abs/2505.16530",
            venue: "arXiv 2025",
            bibtex: `@article{yan2025duffin,
  title={DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection},
  author={Yan, Yuliang and Tang, Haochun and Yan, Shuo and Dai, Enyan},
  journal={arXiv preprint arXiv:2505.16530},
  year={2025}
}`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "Invisible Traces: Using Hybrid Fingerprinting to identify underlying LLMs in GenAI Apps",
            link: "https://arxiv.org/abs/2501.18712",
            venue: "arXiv 2025",
            bibtex: `@misc{bhardwaj2025invisibletracesusinghybrid,
      title={Invisible Traces: Using Hybrid Fingerprinting to identify underlying LLMs in GenAI Apps},
      author={Devansh Bhardwaj and Naman Mishra},
      year={2025},
      eprint={2501.18712},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.18712},
}`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "Detecting Stylistic Fingerprints of Large Language Models",
            link: "https://arxiv.org/abs/2503.01659",
            venue: "arXiv 2025",
            bibtex: `@article{bitton2025detecting,
  title={Detecting Stylistic Fingerprints of Large Language Models},
  author={Bitton, Yehonatan and Bitton, Elad and Nisan, Shai},
  journal={arXiv preprint arXiv:2503.01659},
  year={2025}
}`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models",
            link: "https://arxiv.org/abs/2505.16785",
            venue: "arXiv 2025",
            bibtex: `@article{ren2025cotsrf,
  title={CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models},
  author={Ren, Zhenzhen and Li, GuoBiao and Li, Sheng and Qian, Zhenxing and Zhang, Xinpeng},
  journal={arXiv preprint arXiv:2505.16785},
  year={2025}
}`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "Watermarking language models through language models",
            link: "https://arxiv.org/abs/2411.05091",
            venue: "arXiv 2024",
            bibtex: `@article{dasgupta2024watermarking,
  title={Watermarking language models through language models},
  author={Dasgupta, Agnibh and Tanvir, Abdullah and Zhong, Xin},
  journal={arXiv preprint arXiv:2411.05091},
  year={2024}
}`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "Your Large Language Models Are Leaving Fingerprints",
            link: "https://arxiv.org/abs/2405.14057",
            venue: "arXiv preprint 2024",
            bibtex: `@article{li2024your,
  title={Your Large Language Models Are Leaving Fingerprints},
  author={Li, Jiahao and Zhang, Kaiwen and Wu, Jiayu and Chen, Yufei and Zhang, Tong and Li, Bo and Zhang, Tianwei},
  journal={arXiv preprint arXiv:2405.14057},
  year={2024}
}`
          },
          {
            title: "Behavioral Fingerprinting of Large Language Models",
            link: "https://arxiv.org/abs/2509.04504",
            venue: "arXiv preprint 2025",
            bibtex: `@article{wei2025behavioral,
  title={Behavioral Fingerprinting of Large Language Models},
  author={Wei, Zeyu and Zhang, Hao and Wang, Junjie and Zhang, Yue and Liu, Zhiyuan and Lin, Yankai},
  journal={arXiv preprint arXiv:2509.04504},
  year={2025}
}`
          },
        ],
        promptOptimization: [
          {
            title: "TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification",
            link: "https://aclanthology.org/2024.findings-acl.683/",
            venue: "Findings of ACL 2024",
            bibtex: `@inproceedings{gubri2024trap,
  title={TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification},
  author={Gubri, Martin and Ulmer, Dennis Thomas and Lee, Hwaran and Yun, Sangdoo and Oh, Seong Joon},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2024},
  pages={11496--11517},
  year={2024}
}`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint",
            link: "https://arxiv.org/abs/2501.15509",
            venue: "arXiv 2025",
            bibtex: `@misc{shao2025fitprintfalseclaimresistantmodelownership,
      title={FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint},
      author={Shuo Shao and Haozhe Zhu and Yiming Li and Hongwei Yao and Tianwei Zhang and Zhan Qin},
      year={2025},
      eprint={2501.15509},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2501.15509},
}`,
            surveyTag: "âœðŸ»"
          },
          {
            title:
              "ProFLingo: A Fingerprinting-based Intellectual Property Protection Scheme for Large Language Models",
            link: "https://ieeexplore.ieee.org/abstract/document/10735575/",
            venue: "CNS 2024",
            code: "https://github.com/hengvt/ProFLingo",
            bibtex: `@inproceedings{jin2024proflingo,
                        title={Proflingo: A fingerprinting-based intellectual property protection scheme for large language models},
                        author={Jin, Heng and Zhang, Chaoyu and Shi, Shanghao and Lou, Wenjing and Hou, Y Thomas},
                        booktitle={2024 IEEE Conference on Communications and Network Security (CNS)},
                        pages={1--9},
                        year={2024},
                        organization={IEEE}
                    }`,
            surveyTag: "âœðŸ»"
          },
          {
            title:
              "RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models",
            link: "https://arxiv.org/abs/2505.06304",
            venue: "arXiv 2025",
            bibtex: `@article{zhang2025rap,
                        title={RAP-SM: Robust Adversarial Prompt via Shadow Models for Copyright Verification of Large Language Models},
                        author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
                        journal={arXiv preprint arXiv:2505.06304},
                        year={2025}
                    }`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "RoFL: Robust Fingerprinting of Language Models",
            link: "https://arxiv.org/abs/2505.12682",
            venue: "arXiv 2025",
            code: "https://github.com/yunyuntsa/RoFL",
            bibtex: `@article{tsai2025rofl,
                        title={RoFL: Robust Fingerprinting of Language Models},
                        author={Tsai, Yun-Yun and Guo, Chuan and Yang, Junfeng and van der Maaten, Laurens},
                        journal={arXiv preprint arXiv:2505.12682},
                        year={2025}
                    }`,
            surveyTag: "âœðŸ»"
          },
          {
            title: "FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint",
            link: "https://arxiv.org/abs/2501.15509",
            venue: "arXiv preprint 2025",
            bibtex: `@article{zhang2025fitprint,
  title={FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint},
  author={Zhang, Yichi and Xu, Xuefei Ning and Liang, Han and Zha, Sheng and Wang, Zhangyang},
  journal={arXiv preprint arXiv:2501.15509},
  year={2025}
}`
          },
          {
            title: "SOS! Soft Prompt Attack Against Open-Source Large Language Models",
            link: "https://arxiv.org/abs/2407.03160",
            venue: "arXiv preprint 2024",
            bibtex: `@article{liu2024sos,
  title={SOS! Soft Prompt Attack Against Open-Source Large Language Models},
  author={Liu, Zhihao and Zhang, Zheng and Li, Xiangyu and Ren, Kui and Zhang, Xiangyu},
  journal={arXiv preprint arXiv:2407.03160},
  year={2024}
}`
          },
          {
            title: "ESF: Efficient Sensitive Fingerprinting for Black-Box Tamper Detection of Large Language Models",
            link: "https://aclanthology.org/2025.findings-acl.546.pdf",
            venue: "Findings of ACL 2025",
            bibtex: `@inproceedings{xu2025esf,
  title={ESF: Efficient Sensitive Fingerprinting for Black-Box Tamper Detection of Large Language Models},
  author={Xu, Peng and Zhao, Mengfei and Wang, Han and Wang, Ruoyu and Yang, Yiming and Li, Qian and Song, Jia},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2025},
  pages={9876--9892},
  year={2025}
}`
          },
        ],
      };

      document.addEventListener("DOMContentLoaded", () => {
        // Add papers to their respective containers
        Object.entries(papers).forEach(([category, paperList]) => {
          const container = document.getElementById(`${category}-papers`);
          if (container && paperList.length > 0) {
            paperList.forEach((paper) => {
              container.appendChild(createPaperReference(paper));
            });
          }
        });
      });
    </script>
  </body>
</html>
