<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
     <title>
       Non-invasive Fingerprinting - LLM Copyright Protection Research
     </title>
     <link rel="icon" type="image/svg+xml" href="../assets/logo.svg" />
     <link rel="stylesheet" href="../assets/style.css" />
    <link rel="stylesheet" href="../assets/nav.css" />
    <link rel="stylesheet" href="../assets/footer.css" />
    <link rel="stylesheet" href="../assets/paper-ref.css" />
    <link rel="stylesheet" href="../assets/layout.css" />
    <style>
      .intro-flex-container {
        display: flex;
        gap: 2rem;
        align-items: flex-start;
        margin-top: 1.5rem;
      }
      .intro-text-content {
        flex: 1;
        min-width: 0;
      }
      .intro-image-content {
        flex: 0 0 300px;
      }
      @media (max-width: 768px) {
        .intro-flex-container {
          flex-direction: column;
          gap: 1.5rem;
        }
        .intro-image-content {
          flex: none;
          align-self: center;
          max-width: 250px;
        }
      }
      
      /* Áªü‰∏ÄËÆ∫ÊñáÊù°ÁõÆÂÆΩÂ∫¶ - ‰∏éinvasiveÈ°µÈù¢‰øùÊåÅ‰∏ÄËá¥ */
      .section-card {
        width: 100%;
        max-width: 100%;
        box-sizing: border-box;
      }

      .section-card p {
        margin-bottom: 1.5rem;
        min-height: 3rem; /* ËÆæÁΩÆÊúÄÂ∞èÈ´òÂ∫¶Áªü‰∏ÄÊèèËø∞Âå∫Âüü */
      }

      .paper-list {
        width: 100%;
        max-width: 100%;
        box-sizing: border-box;
        display: block;
      }

      .paper-reference {
        width: 100%;
        max-width: 100%;
        box-sizing: border-box;
        margin: 10px 0;
      }
    </style>
  </head>
  <body>
    <div id="nav-placeholder"></div>

    <div class="main-content">
      <div class="header-section">
        <h1>Non-invasive Fingerprinting</h1>
        <p class="intro-text">
          Non-invasive fingerprinting methods leverage the inherent
          properties of language models without requiring modifications to
          their architecture or training process. Specifically, these
          methods can extract fingerprints from the model's weight space and
          feature space. Additionally, a novel approach based on prompt
          optimization strategies attempts to utilize the model's decision
          boundary characteristics as distinctive fingerprints.
        </p>
      </div>

      <div class="section-card">
        <h2>Parameter Feature as Fingerprint</h2>
        <p>
          Methods that analyze the weight space of language models to identify
          unique patterns and characteristics.
        </p>
        <div id="weightSpace-papers" class="paper-list"></div>
      </div>

      <div class="section-card">
        <h2>Representation Feature as Fingerprint</h2>
        <p>
          Methods that analyze the internal representations of LLMs, including
          activation patterns, hidden states, and output logits, which are
          derived from the data, strategies, and frameworks used during the
          training process. These representations serve as intrinsic features
          for model identification, capturing the unique characteristics of how
          different models process and transform information. The output logits,
          representing the model's prediction probabilities, also reflect the
          model's learned patterns and decision boundaries, making them valuable
          for fingerprinting purposes.
        </p>
        <div id="representationFeatures-papers" class="paper-list"></div>
      </div>

      <div class="section-card">
        <h2>Semantic Feature as Fingerprint</h2>
        <p>
          This category of methods conducts statistical analysis on the content
          generated by different models, exploiting the linguistic patterns and
          semantic preferences exhibited by various LLMs as their unique
          fingerprints.
        </p>
        <div id="semanticFeatures-papers" class="paper-list"></div>
      </div>

      <div class="section-card">
        <h2>Adversarial Example as Fingerprint</h2>
        <p>
          The fundamental process of prompt optimization-based fingerprinting
          can be understood as follows: given an original input and a predefined
          response, the method optimizes the prompt to obtain a final version
          that, when input to the model, produces the predefined response. Since
          this optimization process is tightly coupled with the model's weights,
          the resulting optimized prompt is effective only for the target model
          and ineffective for other unrelated models, thus serving as a stable
          fingerprint feature.
        </p>
        <div id="promptOptimization-papers" class="paper-list"></div>
      </div>
    </div>

    <div id="footer-placeholder"></div>

    <script src="../assets/nav.js"></script>
    <script src="../assets/footer.js"></script>
    <script src="../assets/paper-ref.js"></script>
    <script>
      // Add paper references
      const papers = {
        weightSpace: [
          {
            title: "SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting",
            link: "https://arxiv.org/abs/2512.03620",
            venue: "arXiv 2025",
            bibtex: `@misc{zhangSELFRobustSingular2025,
  title = {SELF: A Robust Singular Value and Eigenvalue Approach for LLM Fingerprinting},
  author = {Zhang, Hanxiu and Zheng, Yue},
  year = {2025},
  number = {arXiv:2512.03620},
  eprint = {2512.03620},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2512.03620},
  archiveprefix = {arXiv}
}`
          },
          {
            title: "Ghost in the Transformer: Detecting Model Reuse with Invariant Spectral Signatures",
            link: "https://arxiv.org/abs/2511.06390",
            venue: "arXiv 2025",
            bibtex: `@misc{wangGhostTransformerDetecting2025,
  title = {Ghost in the Transformer: Detecting Model Reuse with Invariant Spectral Signatures},
  author = {Wang, Suqing and Ma, Ziyang and Xinyi, Li and Li, Zuchao},
  year = {2025},
  number = {arXiv:2511.06390},
  eprint = {2511.06390},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2511.06390},
  archiveprefix = {arXiv}
}`
          },
          {
            title: "AWM: Accurate Weight-Matrix Fingerprint for Large Language Models",
            link: "https://arxiv.org/abs/2510.06738",
            venue: "arXiv 2025",
            bibtex: `@misc{zengAWMAccurateWeightMatrix2025,
  title = {AWM: Accurate Weight-Matrix Fingerprint for Large Language Models},
  author = {Zeng, Boyi and Chen, Lin and He, Ziwei and Wang, Xinbing and Lin, Zhouhan},
  year = {2025},
  number = {arXiv:2510.06738},
  eprint = {2510.06738},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2510.06738},
  archiveprefix = {arXiv}
}`
          },
           {
             title: "Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC",
             link: "https://arxiv.org/abs/2508.06309",
             venue: "arXiv 2025",
             bibtex: `@article{liu2025matrix,
  title={Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC},
  author={Liu, Qichen and Zhang, Tianwei and Ren, Kui and Wang, Bo and Xu, Zhiyong},
  journal={arXiv preprint arXiv:2508.06309},
  year={2025}
}`
           },
          {
            title: "Intrinsic Fingerprint of LLMs: Continue Training is NOT All You Need to Steal A Model!",
            link: "https://arxiv.org/abs/2507.03014",
            venue: "arXiv 2025",
            bibtex: `@article{yoon2025intrinsic,
   title={Intrinsic Fingerprint of LLMs: Continue Training is NOT All You Need to Steal A Model!},
   author={Yoon, Do-hyeon and Chun, Minsoo and Allen, Thomas and M\\\"uller, Hans and Wang, Min and Sharma, Rajesh},
   journal={arXiv preprint arXiv:2507.03014},
   year={2025}
 }`,
            surveyTag: "‚úçüèª"
          },
           {
             title: "HuRef: HUman-REadable Fingerprint for Large Language Models",
             link: "https://arxiv.org/abs/2312.04828",
             venue: "arXiv 2023",
             bibtex: `@article{zeng2023huref,
   title={HuRef: HUman-REadable Fingerprint for Large Language Models},
   author={Zeng, Boyi and Zhou, Chenghu and Wang, Xinbing and Lin, Zhouhan},
   journal={arXiv preprint arXiv:2312.04828},
   year={2023}
 }`,
             surveyTag: "‚úçüèª"
           },
          // ÈöêËóèÊ≠§ËÆ∫Êñá
          /*
          {
            title: "Copy, Right? A Testing Framework for Copyright Protection of Deep Learning Models",
            link: "https://arxiv.org/abs/2112.05588",
            venue: "IEEE S&P 2022",
            bibtex: `@inproceedings{chen2022copy,
   title={Copy, Right? A Testing Framework for Copyright Protection of Deep Learning Models},
   author={Chen, Jialuo and Wang, Jingyi and Peng, Tinglan and Sun, Youcheng and Cheng, Peng and Ji, Shouling and Ma, Xingjun and Li, Bo and Song, Dawn},
   booktitle={Proceedings of the 2022 IEEE Symposium on Security and Privacy (SP)},
   pages={824--841},
   year={2022}
 }`,
            surveyTag: "‚úçüèª"
          },
          */
        ],
        representationFeatures: [
          {
            title: "Every Language Model Has a Forgery-Resistant Signature",
            link: "https://arxiv.org/abs/2510.14086",
            venue: "arXiv 2025",
            bibtex: `@misc{finlaysonEveryLanguageModel2025,
  title = {Every Language Model Has a Forgery-Resistant Signature},
  author = {Finlayson, Matthew and Ren, Xiang and Swayamdipta, Swabha},
  year = {2025},
  number = {arXiv:2510.14086},
  eprint = {2510.14086},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2510.14086},
  archiveprefix = {arXiv}
}`
          },
          {
            title: "SeedPrints: Fingerprints Can Even Tell Which Seed Your Large Language Model Was Trained From",
            link: "https://arxiv.org/abs/2509.26404",
            venue: "arXiv 2025",
            bibtex: `@article{li2025seedprints,
  title={SeedPrints: Fingerprints Can Even Tell Which Seed Your Large Language Model Was Trained From},
  author={Li, Zhenyu and Wang, Han and Zhang, Haolin and Zhou, Jie and Wang, Shuai and Liang, Yuxin and Ma, Ming and Yang, Qiang},
  journal={arXiv preprint arXiv:2509.26404},
  year={2025}
}`
          },
          {
            title: "RouteMark: A Fingerprint for Intellectual Property Attribution in Routing-based Model Merging",
            link: "https://arxiv.org/abs/2508.01784",
            venue: "arXiv 2025",
            bibtex: `@article{huang2025routemark,
  title={RouteMark: A Fingerprint for Intellectual Property Attribution in Routing-based Model Merging},
  author={Huang, Liang and Yang, Ruoxi and Zhang, Yifan and Zhang, Xinpeng and Qian, Zhenxing},
  journal={arXiv preprint arXiv:2508.01784},
  year={2025}
}`
          },
          // ÈöêËóèÊ≠§ËÆ∫Êñá
          /*
          {
            title: "Riemannian-Geometric Fingerprints of Generative Models",
            link: "https://arxiv.org/abs/2506.22802",
            venue: "arXiv 2025",
            bibtex: `@article{song2025riemannian,
   title={Riemannian-Geometric Fingerprints of Generative Models},
   author={Song, Hae Jin and Itti, Laurent},
   journal={arXiv preprint arXiv:2506.22802},
   year={2025}
 }`,
            surveyTag: "‚úçüèª"
          },
          */
          {
            title: "Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification",
            link: "https://arxiv.org/abs/2506.01631",
            venue: "arXiv 2025",
            bibtex: `@article{wu2025gradient,
   title={Gradient-Based Model Fingerprinting for LLM Similarity Detection and Family Classification},
   author={Wu, Zehao and Zhao, Yanjie and Wang, Haoyu},
   journal={arXiv preprint arXiv:2506.01631},
   year={2025}
 }`,
            surveyTag: "‚úçüèª"
          },
          {
            title: "LLMs Have Rhythm: Fingerprinting Large Language Models Using Inter-Token Times and Network Traffic Analysis",
            link: "https://arxiv.org/abs/2502.20589",
            venue: "arXiv 2025",
            bibtex: `@article{alhazbi2025llms,
   title={LLMs Have Rhythm: Fingerprinting Large Language Models Using Inter-Token Times and Network Traffic Analysis},
   author={Alhazbi, Saeif and Hussain, Ahmed Mohamed and Oligeri, Gabriele and Papadimitratos, Panos},
   journal={arXiv preprint arXiv:2502.20589},
   year={2025}
 }`,
            surveyTag: "‚úçüèª"
          },
          {
            title: "Independence Tests for Language Models",
            link: "https://arxiv.org/abs/2502.12292",
            venue: "arXiv 2025",
            bibtex: `@article{chang2025independence,
  title={Independence Tests for Language Models},
  author={Chang, Jonathan D and Qi, Zhengyuan and Zhang, Xiang and Wang, William Yang},
  journal={arXiv preprint arXiv:2502.12292},
  year={2025}
}`
          },
          {
            title: "FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting",
            link: "https://arxiv.org/abs/2501.16029",
            venue: "arXiv 2025",
            bibtex: `@article{liu2025fdllm,
  title={FDLLM: A Dedicated Detector for Black-Box LLMs Fingerprinting},
  author={Liu, Han and Wang, Jinpeng and Zhou, Xin and Zhang, Hui and Xu, Shujian and Yang, Zhendong},
  journal={arXiv preprint arXiv:2501.16029},
  year={2025}
}`
          },
          {
            title: "Reef: Representation encoding fingerprints for large language models",
            link: "https://arxiv.org/abs/2410.14273",
            venue: "arXiv 2024",
            bibtex: `@article{zhang2024reef,
   title={Reef: Representation encoding fingerprints for large language models},
   author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
   journal={arXiv preprint arXiv:2410.14273},
   year={2024}
 }`,
            surveyTag: "‚úçüèª"
          },
          {
            title: "EasyDetector: Using Linear Probe to Detect the Provenance of Large Language Models",
            link: "https://www.computer.org/csdl/proceedings-article/trustcom/2024/062000c410/25DIa1Go9DG",
            venue: "IEEE TrustCom 2024",
            bibtex: `@inproceedings{yang2024easydetector,
  title={EasyDetector: Using Linear Probe to Detect the Provenance of Large Language Models},
  author={Yang, Tianyu and Zhang, Rui and Zhang, Xin and Ren, Kui},
  booktitle={2024 IEEE 23rd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)},
  pages={410--418},
  year={2024},
  organization={IEEE}
}`
          },
          {
            title: "zkLLM: Zero Knowledge Proofs for Large Language Models",
            link: "https://arxiv.org/abs/2404.16109",
            venue: "ACM CCS 2024",
            bibtex: `@article{sun2024zkllm,
  title={zkLLM: Zero Knowledge Proofs for Large Language Models},
  author={Sun, Haochen and Li, Jason and Zhang, Hongyang},
  journal={arXiv preprint arXiv:2404.16109},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          // ÈöêËóèÊ≠§ËÆ∫Êñá
          /*
          {
            title: "Copy, Right? A Testing Framework for Copyright Protection of Deep Learning Models",
            link: "https://arxiv.org/abs/2112.05588",
            venue: "IEEE S&P 2022",
            bibtex: `@inproceedings{chen2022copy,
   title={Copy, Right? A Testing Framework for Copyright Protection of Deep Learning Models},
   author={Chen, Jialuo and Wang, Jingyi and Peng, Tinglan and Sun, Youcheng and Cheng, Peng and Ji, Shouling and Ma, Xingjun and Li, Bo and Song, Dawn},
   booktitle={Proceedings of the 2022 IEEE Symposium on Security and Privacy (SP)},
   pages={824--841},
   year={2022}
 }`,
            surveyTag: "‚úçüèª"
          },
          */
        ],
        semanticFeatures: [
          {
            title: "Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation",
            link: "https://arxiv.org/abs/2510.06605",
            venue: "arXiv 2025",
            bibtex: `@misc{shaoReadingLinesReliable2025,
  title = {Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation},
  author = {Shao, Shuo and Li, Yiming and Yao, Hongwei and Chen, Yifei and Yang, Yuchen and Qin, Zhan},
  year = {2025},
  publisher = {arXiv},
  doi = {10.48550/ARXIV.2510.06605}
}`
          },
          {
            title: "PhyloLM: Inferring the Phylogeny of Large Language Models and Predicting Their Performances in Benchmarks",
            link: "https://arxiv.org/abs/2404.04671",
            venue: "ICLR 2025",
            bibtex: `@inproceedings{yaxPhyloLMInferringPhylogeny2025,
  title = {PhyloLM: Inferring the Phylogeny of Large Language Models and Predicting Their Performances in Benchmarks},
  booktitle = {Proceedings of the Thirteenth International Conference on Learning Representations},
  author = {Yax, Nicolas and Oudeyer, Pierre-Yves and Palminteri, Stefano},
  year = {2025},
  eprint = {2404.04671},
  primaryclass = {cs},
  publisher = {OpenReview.net},
  doi = {10.48550/arXiv.2404.04671},
  archiveprefix = {arXiv}
}`
          },
          {
            title: "FLiPS: Few-Shot Fingerprinting of LLMs via Pseudorandom Sequences",
            link: "https://openreview.net/forum?id=5Jd7TObzee",
            venue: "ICLR 2025 [Under Review]",
            bibtex: `@inproceedings{anonymous2025flips,
  title = {FLiPS: Few-Shot Fingerprinting of LLMs via Pseudorandom Sequences},
  author = {Anonymous},
  booktitle = {Submitted to The Fourteenth International Conference on Learning Representations},
  year = {2025},
  url = {https://openreview.net/forum?id=5Jd7TObzee},
  note = {[Under Review]}
}`
          },
          {
            title: "Natural Fingerprints of Large Language Models",
            link: "https://arxiv.org/abs/2504.14871",
            venue: "arXiv 2025",
            bibtex: `@misc{suzukiNaturalFingerprintsLarge2025,
  title = {Natural Fingerprints of Large Language Models},
  author = {Suzuki, Teppei and Ri, Ryokan and Takase, Sho},
  year = {2025},
  number = {arXiv:2504.14871},
  eprint = {2504.14871},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2504.14871},
  archiveprefix = {arXiv}
}`
          },
          {
            title: "LLM DNA: Tracing Model Evolution via Functional Representations",
            link: "https://arxiv.org/pdf/2509.24496",
            venue: "arXiv 2025",
            bibtex: `@article{wang2025llmdna,
  title={LLM DNA: Tracing Model Evolution via Functional Representations},
  author={Wang, Yiming and He, Ming and Zhang, Ruibo and Tang, Haochun and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2509.24496},
  year={2025}
}`
          },
          {
            title: "Behavioral Fingerprinting of Large Language Models",
            link: "https://arxiv.org/abs/2509.04504",
            venue: "arXiv 2025",
            bibtex: `@article{wei2025behavioral,
  title={Behavioral Fingerprinting of Large Language Models},
  author={Wei, Zeyu and Zhang, Hao and Wang, Junjie and Zhang, Yue and Liu, Zhiyuan and Lin, Yankai},
  journal={arXiv preprint arXiv:2509.04504},
  year={2025}
}`
          },
          {
            title: "CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models",
            link: "https://arxiv.org/abs/2505.16785",
            venue: "arXiv 2025",
            bibtex: `@article{ren2025cotsrf,
  title={CoTSRF: Utilize Chain of Thought as Stealthy and Robust Fingerprint of Large Language Models},
  author={Ren, Zhenzhen and Li, GuoBiao and Li, Sheng and Qian, Zhenxing and Zhang, Xinpeng},
  journal={arXiv preprint arXiv:2505.16785},
  year={2025}
}`,
            surveyTag: "‚úçüèª"
          },
          {
            title: "DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection",
            link: "https://arxiv.org/abs/2505.16530",
            venue: "arXiv 2025",
            bibtex: `@article{yan2025duffin,
  title={DuFFin: A Dual-Level Fingerprinting Framework for LLMs IP Protection},
  author={Yan, Yuliang and Tang, Haochun and Yan, Shuo and Dai, Enyan},
  journal={arXiv preprint arXiv:2505.16530},
  year={2025}
}`,
            surveyTag: "‚úçüèª"
          },
          {
            title: "Detecting Stylistic Fingerprints of Large Language Models",
            link: "https://arxiv.org/abs/2503.01659",
            venue: "arXiv 2025",
            bibtex: `@article{bitton2025detecting,
  title={Detecting Stylistic Fingerprints of Large Language Models},
  author={Bitton, Yehonatan and Bitton, Elad and Nisan, Shai},
  journal={arXiv preprint arXiv:2503.01659},
  year={2025}
}`,
            surveyTag: "‚úçüèª"
          },
          {
            title: "Invisible Traces: Using Hybrid Fingerprinting to identify underlying LLMs in GenAI Apps",
            link: "https://arxiv.org/abs/2501.18712",
            venue: "arXiv 2025",
            bibtex: `@misc{bhardwaj2025invisibletracesusinghybrid,
      title={Invisible Traces: Using Hybrid Fingerprinting to identify underlying LLMs in GenAI Apps},
      author={Devansh Bhardwaj and Naman Mishra},
      year={2025},
      eprint={2501.18712},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2501.18712},
}`,
            surveyTag: "‚úçüèª"
          },
          // Hidden: Watermarking language models through language models
          // {
          //   title: "Watermarking language models through language models",
          //   link: "https://arxiv.org/abs/2411.05091",
          //   venue: "arXiv 2024",
          //   bibtex: `@article{dasgupta2024watermarking,
          //     title={Watermarking language models through language models},
          //     author={Dasgupta, Agnibh and Tanvir, Abdullah and Zhong, Xin},
          //     journal={arXiv preprint arXiv:2411.05091},
          //     year={2024}
          //   }`,
          //   surveyTag: "‚úçüèª"
          // },
          {
            title: "LLMMap: Fingerprinting for Large Language Models",
            link: "https://arxiv.org/abs/2407.15847",
            venue: "arXiv 2024",
            bibtex: `@article{pasquini2024llmmap,
  title={LLMMap: Fingerprinting for Large Language Models},
  author={Pasquini, Dario and Kornaropoulos, Evgenios M and Ateniese, Giuseppe},
  journal={arXiv preprint arXiv:2407.15847},
  year={2024}
}`,
            surveyTag: "‚úçüèª"
          },
          {
            title: "A Fingerprint for Large Language Models",
            link: "https://arxiv.org/abs/2407.01235",
            venue: "arXiv 2024",
            bibtex: `@misc{yang2024fingerprintlargelanguagemodels,
      title={A Fingerprint f
      or Large Language Models}, 
      author={Zhiguang Yang and Hanzhou Wu},
      year={2024},
      eprint={2407.01235},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2407.01235}, 
}`
          },
          {
            title: "Your Large Language Models Are Leaving Fingerprints",
            link: "https://arxiv.org/abs/2405.14057",
            venue: "arXiv 2024",
            bibtex: `@article{li2024your,
  title={Your Large Language Models Are Leaving Fingerprints},
  author={Li, Jiahao and Zhang, Kaiwen and Wu, Jiayu and Chen, Yufei and Zhang, Tong and Li, Bo and Zhang, Tianwei},
  journal={arXiv preprint arXiv:2405.14057},
  year={2024}
}`
          },
        ],
        promptOptimization: [
          {
            title:
              "SRAF: Stealthy and Robust Adversarial Fingerprint for Copyright Verification of Large Language Models",
            link: "https://arxiv.org/abs/2505.06304",
            venue: "arXiv 2026",
            bibtex: `@misc{wangSRAFStealthyRobust2026,
  title = {SRAF: Stealthy and Robust Adversarial Fingerprint for Copyright Verification of Large Language Models},
  author = {Wang, Zhebo and Xu, Zhenhua and Li, Maike and Xing, Wenpeng and Hu, Chunqiang and Zhi, Chen and Han, Meng},
  year = {2026},
  number = {arXiv:2505.06304},
  eprint = {2505.06304},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.06304},
  archiveprefix = {arXiv}
}`,
            surveyTag: "‚úçüèª"
          },
          {
            title: "Fingerprinting LLMs via Prompt Injection",
            link: "https://arxiv.org/abs/2509.25448",
            venue: "arXiv 2025",
            bibtex: `@misc{huFingerprintingLLMsPrompt2025,
  title = {Fingerprinting LLMs via Prompt Injection},
  author = {Hu, Yuepeng and Jiang, Zhengyuan and Li, Mengyuan and Ahmed, Osama and Huang, Zhicong and Hong, Cheng and Gong, Neil},
  year = {2025},
  number = {arXiv:2509.25448},
  eprint = {2509.25448},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2509.25448},
  archiveprefix = {arXiv}
}`
          },
          {
            title: "ESF: Efficient Sensitive Fingerprinting for Black-Box Tamper Detection of Large Language Models",
            link: "https://aclanthology.org/2025.findings-acl.546.pdf",
            venue: "Findings of ACL 2025",
            bibtex: `@inproceedings{xu2025esf,
  title={ESF: Efficient Sensitive Fingerprinting for Black-Box Tamper Detection of Large Language Models},
  author={Xu, Peng and Zhao, Mengfei and Wang, Han and Wang, Ruoyu and Yang, Yiming and Li, Qian and Song, Jia},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2025},
  pages={9876--9892},
  year={2025}
}`
          },
          {
            title: "RoFL: Robust Fingerprinting of Language Models",
            link: "https://arxiv.org/abs/2505.12682",
            venue: "arXiv 2025",
            code: "https://github.com/yunyuntsa/RoFL",
            bibtex: `@article{tsai2025rofl,
                        title={RoFL: Robust Fingerprinting of Language Models},
                        author={Tsai, Yun-Yun and Guo, Chuan and Yang, Junfeng and van der Maaten, Laurens},
                        journal={arXiv preprint arXiv:2505.12682},
                        year={2025}
                    }`,
            surveyTag: "‚úçüèª"
          },
          // ÈöêËóèÊ≠§ËÆ∫Êñá
          /*
          {
            title: "FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint",
            link: "https://arxiv.org/abs/2501.15509",
            venue: "arXiv 2025",
            bibtex: `@misc{shao2025fitprintfalseclaimresistantmodelownership,
      title={FIT-Print: Towards False-claim-resistant Model Ownership Verification via Targeted Fingerprint},
      author={Shuo Shao and Haozhe Zhu and Yiming Li and Hongwei Yao and Tianwei Zhang and Zhan Qin},
      year={2025},
      eprint={2501.15509},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2501.15509},
}`,
            surveyTag: "‚úçüèª"
          },
          */
          {
            title:
              "ProFLingo: A Fingerprinting-based Intellectual Property Protection Scheme for Large Language Models",
            link: "https://ieeexplore.ieee.org/abstract/document/10735575/",
            venue: "CNS 2024",
            code: "https://github.com/hengvt/ProFLingo",
            bibtex: `@inproceedings{jin2024proflingo,
                        title={Proflingo: A fingerprinting-based intellectual property protection scheme for large language models},
                        author={Jin, Heng and Zhang, Chaoyu and Shi, Shanghao and Lou, Wenjing and Hou, Y Thomas},
                        booktitle={2024 IEEE Conference on Communications and Network Security (CNS)},
                        pages={1--9},
                        year={2024},
                        organization={IEEE}
                    }`,
            surveyTag: "‚úçüèª"
          },
          {
            title: "SOS! Soft Prompt Attack Against Open-Source Large Language Models",
            link: "https://arxiv.org/abs/2407.03160",
            venue: "arXiv 2024",
            bibtex: `@article{liu2024sos,
  title={SOS! Soft Prompt Attack Against Open-Source Large Language Models},
  author={Liu, Zhihao and Zhang, Zheng and Li, Xiangyu and Ren, Kui and Zhang, Xiangyu},
  journal={arXiv preprint arXiv:2407.03160},
  year={2024}
}`
          },
          {
            title: "TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification",
            link: "https://aclanthology.org/2024.findings-acl.683/",
            venue: "Findings of ACL 2024",
            bibtex: `@inproceedings{gubri2024trap,
  title={TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box Identification},
  author={Gubri, Martin and Ulmer, Dennis Thomas and Lee, Hwaran and Yun, Sangdoo and Oh, Seong Joon},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2024},
  pages={11496--11517},
  year={2024}
}`,
            surveyTag: "‚úçüèª"
          },
        ],
      };

      document.addEventListener("DOMContentLoaded", () => {
        // Add papers to their respective containers
        Object.entries(papers).forEach(([category, paperList]) => {
          const container = document.getElementById(`${category}-papers`);
          if (container && paperList.length > 0) {
            paperList.forEach((paper) => {
              container.appendChild(createPaperReference(paper));
            });
          }
        });
      });
    </script>
  </body>
</html>
