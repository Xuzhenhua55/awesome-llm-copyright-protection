<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
     <title>Invasive Fingerprinting - LLM Copyright Protection Research</title>
     <link rel="icon" type="image/svg+xml" href="../assets/logo.svg" />
     <link rel="stylesheet" href="../assets/style.css" />
    <link rel="stylesheet" href="../assets/nav.css" />
    <link rel="stylesheet" href="../assets/footer.css" />
    <link rel="stylesheet" href="../assets/paper-ref.css" />
    <link rel="stylesheet" href="../assets/layout.css" />
    <style>
      /* Unify paper entry widths across sections */
      .section-card {
        width: 100%;
        max-width: 100%;
        box-sizing: border-box;
        position: relative;
        z-index: 1;
      }

      .section-card p {
        margin-bottom: 1.5rem;
        min-height: 3rem; /* normalize description block height */
      }

      .paper-list {
        width: 100%;
        max-width: 100%;
        box-sizing: border-box;
        display: block;
      }

      .paper-reference {
        width: 100%;
        max-width: 100%;
        box-sizing: border-box;
        margin: 10px 0;
      }
      
      /* é˜²æ­¢section-card hoveræ—¶è¦†ç›–å·¦ä¾§å¯¼èˆª */
      .section-card:hover {
        transform: none;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05);
      }
    </style>
  </head>
  <body>
    <div id="nav-placeholder"></div>

    <div class="main-content">
      <div class="header-section">
        <h1>Invasive Fingerprinting</h1>
        <p class="intro-text">
          Invasive model fingerprinting techniques typically involve embedding
          information into the model's weights to construct fingerprint
          features. The purpose is to achieve model authentication and copyright
          protection. The general paradigm is to embed fingerprint information
          into the model and subsequently extract it from the model.
        </p>
      </div>

      <div class="section-card">
        <h2>Weight Watermark As Fingerprint</h2>
        <p>
          Embedding watermark information into model weights is a widely used
          fingerprinting technique, where the watermark serves as a traceable
          model fingerprint. By adjusting parameters during the training phase,
          fingerprint information can be embedded into weights, biases, or other
          model parameters. By comparing the parameter fingerprints extracted
          from a suspicious model with those in the owner's model, the owner can
          verify the model's identity.
        </p>
        <div id="weightWatermark-papers" class="paper-list"></div>
      </div>


      <div class="section-card">
        <h2>Backdoor Watermark As Fingerprint</h2>
        <p>
          In practical scenarios, the model parameters and network architectures
          in commercial services are usually kept secret, so the above methods
          of embedding fingerprints into model parameters and network layers are
          often not feasible. Therefore, the fingerprinting technique based on
          backdoor watermark is more suitable for black-box environments and is
          more widely used in practical applications. In this scenario, the
          backdoor watermark, as a verifiable model fingerprint, is referred to
          as a backdoor fingerprint. The backdoor fingerprint mainly constructs
          special backdoor datasets and implants them into the model, enabling
          the backdoored model to trigger predefined backdoor responses and
          extract fingerprint information when encountering backdoor triggers
          that meet the trigger conditions.
        </p>
        <div id="backdoorWatermark-papers" class="paper-list"></div>
        
        <h3>Knowledge Editing</h3>
        <p>
          Knowledge Editing provides a localized mechanism for embedding controllable fingerprint behaviors within backdoor-based frameworks. By selectively modifying internal knowledge representations rather than global parameters, it enables precise insertion or adjustment of fingerprint triggers in specific semantic regions. This approach preserves the model's overall performance while allowing the fingerprint to manifest as a verifiable micro-knowledge unit that can be activated under defined trigger conditions, offering a flexible and black-boxâ€“compatible means of fingerprint implantation and verification.
        </p>
        <div id="knowledgeEditing-papers" class="paper-list"></div>
      </div>
    </div>

    <div id="footer-placeholder"></div>

    <script src="../assets/nav.js"></script>
    <script src="../assets/footer.js"></script>
    <script src="../assets/paper-ref.js"></script>
    <script>
      // Add paper references
      const papers = {
        weightWatermark: [
          {
            title:
              "Invariant-based Robust Weights Watermark for Large Language Models",
            link: "https://arxiv.org/abs/2507.08288",
            venue: "arXiv 2025",
            bibtex: `@misc{guoInvariantbasedRobustWeights2025,
  title = {Invariant-Based Robust Weights Watermark for Large Language Models},
  author = {Guo, Qingxiao and Zhu, Xinjie and Ma, Yilong and Jin, Hui and Wang, Yunhao and Zhang, Weifeng and Guo, Xiaobing},
  year = {2025},
  number = {arXiv:2507.08288},
  eprint = {2507.08288},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2507.08288},
  archiveprefix = {arXiv}
}`,
            surveyTag: "âœðŸ»",
          },
          // éšè—æ­¤è®ºæ–‡
          /*
          {
            title: "Towards the Resistance of Neural Network Watermarking to Fine-tuning",
            link: "https://arxiv.org/abs/2505.01007",
            venue: "arXiv 2025.05",
            bibtex: `@article{yang2025resistance,
  title={Towards the Resistance of Neural Network Watermarking to Fine-tuning},
  author={Yang, Xiaofan and Zhao, Yuxin and Li, Sheng and Qian, Zhenxing and Zhang, Xinpeng},
  journal={arXiv preprint arXiv:2505.01007},
  year={2025}
}`
          },
          */
          {
            title:
              "Robust and Efficient Watermarking of Large Language Models Using Error Correction Codes",
            link: "https://petsymposium.org/popets/2025/popets-2025-0126.pdf",
            venue: "PoPETs 2025",
            bibtex: `@article{block2025robust,
    title={Robust and Efficient Watermarking of Large Language Models Using Error Correction Codes},
    author={Block, Adam and Sekhari, Ayush and Rakhlin, Alexander},
    journal={Proceedings on Privacy Enhancing Technologies (PoPETs) 2025},
    year={2025}
  }`,
            surveyTag: "âœðŸ»",
          },
          {
            title:
              "EmMark: Robust watermarks for IP protection of embedded quantized large language models",
            link: "https://dl.acm.org/doi/abs/10.1145/3649329.3655674",
            venue: "DAC 2024",
            bibtex: `@inproceedings{zhang2024emmark,
  title={EmMark: Robust watermarks for IP protection of embedded quantized large language models},
  author={Zhang, Ruisi and Koushanfar, Farinaz},
  booktitle={Proceedings of the 61st ACM/IEEE Design Automation Conference},
  pages={1--6},
  year={2024}
}`,
            surveyTag: "âœðŸ»",
          },
          {
            title: "Functional Invariants to Watermark Large Transformers",
            link: "https://arxiv.org/abs/2310.11446",
            venue: "ICASSP 2024",
            bibtex: `@inproceedings{fernandez2023functional,
  title={Functional Invariants to Watermark Large Transformers},
  author={Fernandez, Pierre and Couairon, Guillaume and Furon, Teddy and Douze, Matthijs},
  booktitle={ICASSP 2024},
  year={2023}
}`,
            surveyTag: "âœðŸ»",
          },
        ], // Weight Watermark papers
        backdoorWatermark: [
          {
            title: "DNF: Dual-Layer Nested Fingerprinting for Large Language Model Intellectual Property Protection",
            link: "https://arxiv.org/abs/2601.08223",
            venue: "ICASSP 2026",
            bibtex: `@misc{xu2026dnfduallayernestedfingerprinting,
  title={DNF: Dual-Layer Nested Fingerprinting for Large Language Model Intellectual Property Protection},
  author={Zhenhua Xu and Yiran Zhao and Mengting Zhong and Dezhang Kong and Changting Lin and Tong Qiao and Meng Han},
  year={2026},
  eprint={2601.08223},
  archivePrefix={arXiv},
  primaryClass={cs.CR},
  url={https://arxiv.org/abs/2601.08223}
}`
          },
          {
            title: "CLMTracing: Black-box User-level Watermarking for Code Language Model Tracing",
            link: "https://aclanthology.org/2025.emnlp-main.1475/",
            venue: "EMNLP 2025",
            bibtex: `@inproceedings{zhang-etal-2025-clmtracing,
  title={CLMTracing: Black-box User-level Watermarking for Code Language Model Tracing},
  author={Zhang, Boyu and He, Ping and Du, Tianyu and Zhang, Xuhong and Yun, Lei and Chow, Kingsum and Yin, Jianwei},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  pages={28962--28978},
  year={2025},
  publisher = "Association for Computational Linguistics",
  doi = "10.18653/v1/2025.emnlp-main.1475"
}`
          },
          {
            title: "ImF: Implicit Fingerprint for Large Language Models",
            link: "https://arxiv.org/abs/2503.21805",
            venue: "arXiv 2025.03-2025.08",
            bibtex: `@article{zhang2025imf,
  title={ImF: Implicit Fingerprint for Large Language Models},
  author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2503.21805},
  year={2025}
}`,
            surveyTag: "âœðŸ»",
          },
          {
            title: "CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor",
            link: "https://aclanthology.org/2025.emnlp-main.356/",
            venue: "EMNLP 2025",
            code: "https://github.com/Xuzhenhua55/CTCC",
            bibtex: `@inproceedings{xu2025ctcc,
  title={CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor},
  author={Xu, Zhenhua and Zhao, Xixiang and Yue, Xubin and Tian, Shengwei and Lin, Changting and Han, Meng},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  pages={6978--7000},
  year={2025},
  publisher = "Association for Computational Linguistics",
  doi = "10.18653/v1/2025.emnlp-main.356"
}`
          },
          {
            title:
              "UTF: Under-trained Tokens as Fingerprints â€” A Novel Approach to LLM Identification",
            link: "https://aclanthology.org/2025.llmsec-1.1/",
            venue: "LLMSEC 2025",
            code: "https://anonymous.4open.science/r/fingerprint-2BCE/README.md",
            bibtex: `@inproceedings{cai-etal-2025-utf,
  title={UTF: Under-trained Tokens as Fingerprints --- a Novel Approach to LLM Identification},
  author={Cai, Jiacheng and Yu, Jiahao and Shao, Yangguang and Wu, Yuhang and Xing, Xinyu},
  booktitle={Proceedings of the The First Workshop on LLM Security (LLMSEC)},
  month={aug},
  year={2025},
  address={Vienna, Austria},
  publisher={Association for Computational Linguistics},
  url={https://aclanthology.org/2025.llmsec-1.1/},
  pages={1--6}
}`,
            surveyTag: "âœðŸ»",
          },
          {
            title:
              "MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models",
            link: "https://aclanthology.org/2025.acl-long.342/",
            venue: "ACL 2025",
            bibtex: `@inproceedings{yamabe2025mergeprint,
  title={MERGEPRINT: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models},
  author={Yamabe, Shojiro and Waseda, Futa Kai and Takahashi, Tsubasa and Wataoka, Koki},
  booktitle={Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={6894--6916},
  year={2025} 
}`,
            surveyTag: "âœðŸ»",
          },
          {
            title: "Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge",
            link: "https://aclanthology.org/2025.findings-acl.736/",
            venue: "Findings of ACL 2025",
            bibtex: `@article{liu2025robust,
  title={Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge},
  author={Liu, Runlin and Zhao, Yuxin and Chen, Jialuo and Ma, Xingjun},
  journal={arXiv preprint arXiv:2503.04036},
  year={2025}
}`
          },
          {
            title: "Beyond Dataset Watermarking: Model-Level Copyright Protection for Code Summarization Models",
            link: "https://dl.acm.org/doi/10.1145/3696410.3714641",
            venue: "ACM FSE 2025",
            bibtex: `@inproceedings{wang2025beyond,
  title={Beyond Dataset Watermarking: Model-Level Copyright Protection for Code Summarization Models},
  author={Wang, Qiang and Zhao, Xiaoqing and Wang, Xin and Liu, Hongyu},
  booktitle={Proceedings of the 33rd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  pages={1--12},
  year={2025},
  organization={ACM}
}`
          },
          {
            title: "Scalable Fingerprinting of Large Language Models",
            link: "https://neurips.cc/virtual/2025/loc/san-diego/128595",
            venue: "NeurIPS 2025",
            bibtex: `@inproceedings{nasery2025scalable,
title={Scalable Fingerprinting of Large Language Models},
author={Anshul Nasery and Jonathan Hayase and Creston Brooks and Peiyao Sheng and Himanshu Tyagi and Pramod Viswanath and Sewoong Oh},
booktitle={The 1st Workshop on GenAI Watermarking},
year={2025},
url={https://openreview.net/forum?id=ImrmzMDq5z}
}`,
            surveyTag: "âœðŸ»",
          },
          {
            title: "NSmark: Null Space Based Black-box Watermarking Defense Framework for Language Models",
            link: "https://openreview.net/pdf?id=6IfvMfNYrv",
            venue: "WMARK@ICLR2025",
            code: "https://github.com/dongdongzhaoUP/NSmark",
            bibtex: `@inproceedings{zhaonsmark,
  title={NSmark: Null Space Based Black-box Watermarking Defense Framework for Language Models},
  author={Zhao, Haodong and Hu, Jinming and Li, Peixuan and Li, Fangqi and Sha, Jinrui and Ju, Tianjie and Zhang, Zhuosheng and Liu, Gongshen and others},
  booktitle={The 1st Workshop on GenAI Watermarking},
  year={2025}
}`,
          },
          // éšè—æ­¤è®ºæ–‡
          /*
          {
            title: "Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution",
            link: "https://www.ndss-symposium.org/ndss-paper/explanation-as-a-watermark-towards-harmless-and-multi-bit-model-ownership-verification-via-watermarking-feature-attribution/",
            venue: "NDSS 2025",
            bibtex: `@article{zhang2024explanation,
  title={Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution},
  author={Zhang, Yifeng and Sun, Yifan and Lu, Yunchao and Zhang, Xiangyu and Wu, Baoyuan},
  journal={arXiv preprint arXiv:2405.04825},
  year={2024}
}`
          },
          */
          {
            title: "InSty: A Robust Multi-Level Cross-Granularity Fingerprint Embedding Algorithm for Multi-Turn Dialogue in Large Language Models",
            link: "https://www.sciengine.com/SSI/doi/10.1360/SSI-2025-0022",
            venue: "SCIS 2025",
            bibtex: `@article{li2025insty,
  title={InSty: A Robust Multi-Level Cross-Granularity Fingerprint Embedding Algorithm for Multi-Turn Dialogue in Large Language Models},
  author={Li, Rui and Zhang, Yuxiang and Xu, Shicheng and Qian, Zhenxing and Zhang, Xinpeng},
  journal={Science China Information Sciences},
  year={2025},
  doi={10.1360/SSI-2025-0022}
}`
          },
          {
            title: "TIBW: Task-Independent Backdoor Watermarking with Fine-Tuning Resilience for Pre-Trained Language Models",
            link: "https://www.mdpi.com/2227-7390/13/2/272",
            venue: "MDPI 2025",
            bibtex: `@article{zhao2025tibw,
  title={TIBW: Task-Independent Backdoor Watermarking with Fine-Tuning Resilience for Pre-Trained Language Models},
  author={Zhao, Meng and Zhu, Yujie and Wang, Yuyang and Li, Rui and Zhang, Qian},
  journal={Mathematics},
  volume={13},
  number={2},
  pages={272},
  year={2025},
  publisher={MDPI}
}`
          },
          {
            title:
              "Hey, That's My Model!Introducing Chain & Hash,An LLM Fingerprinting Technique",
            link: "https://arxiv.org/abs/2407.10887",
            venue: "arXiv 2024.07-2025.06",
            bibtex: `@article{russinovich2024hey,
  title={Hey, That\'s My Model! Introducing Chain \& Hash, An LLM Fingerprinting Technique},
  author={Russinovich, Mark and Salem, Ahmed},
  journal={arXiv preprint arXiv:2407.10887},
  year={2024}
}`,
            surveyTag: "âœðŸ»",
          },
          {
            title: "Instructional Fingerprinting of Large Language Models",
            link: "https://aclanthology.org/2024.naacl-long.180/",
            venue: "NAACL 2024",
            code: "https://cnut1648.github.io/Model-Fingerprint",
            bibtex: `@inproceedings{xu2024instructional,
  title={Instructional Fingerprinting of Large Language Models},
  author={Xu, Jiashu and Wang, Fei and Ma, Mingyu and Koh, Pang Wei and Xiao, Chaowei and Chen, Muhao},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={3277--3306},
  year={2024}
}`,
            surveyTag: "âœðŸ»",
          },
          {
            title: "Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning",
            link: "https://arxiv.org/abs/2402.14883",
            venue: "arXiv 2024.02-2024.06",
            bibtex: `@article{li2024double,
  title={Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning},
  author={Li, Shen and Yao, Liuyi and Gao, Jinyang and Zhang, Lan and Li, Yaliang},
  journal={arXiv preprint arXiv:2402.14883},
  year={2024}
}`,
            surveyTag: "âœðŸ»",
          },
          {
            title: "Turning Your Strength into Watermark: Watermarking Large Language Model via Knowledge Injection",
            link: "https://zjzac.github.io/publications/pdf/tifs25-ls.pdf",
            venue: "TIFS 2025",
            bibtex: `@misc{li2023turningyourstrengthintowatermark,
  title={Turning Your Strength into Watermark: Watermarking Large Language Model via Knowledge Injection}, 
  author={Shuai Li and Kejiang Chen and Kunsheng Tang and Jie Zhang and Weiming Zhang and Nenghai Yu and Kai Zeng},
  year={2023},
  eprint={2311.09535},
  archivePrefix={arXiv},
  primaryClass={cs.CR},
  url={https://arxiv.org/abs/2311.09535}
}`,
          },   
          {
            title: "PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models",
            link: "https://ojs.aaai.org/index.php/AAAI/article/view/26750",
            venue: "AAAI 2023",
            bibtex: `@inproceedings{li2023plmmark,
  title={PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models},
  author={Li, Peixuan and Cheng, Pengzhou and Li, Fangqi and Du, Wei and Zhao, Haodong and Liu, Gongshen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence 2023},
  pages={14991--14999},
  year={2023}
}`,
            surveyTag: "âœðŸ»",
          },
        ], // Backdoor Watermark papers
        knowledgeEditing: [
          {
            title: "PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement",
            link: "https://aclanthology.org/anthology-files/pdf/findings/2025.findings-emnlp.204.pdf",
            venue: "Findings of EMNLP 2025",
            bibtex: `@inproceedings{yue-etal-2025-pree,
  title={PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement},
  author={Yue, Xubin and Xu, Zhenhua and Xing, Wenpeng and Yu, Jiahui and Li, Mohan and Han, Meng},
  booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2025",
  doi = "10.18653/v1/2025.findings-emnlp.204",
  pages = "3794--3804",
  publisher = "Association for Computational Linguistics",
  year={2025}
}`
          },
          {
            title: "FPEdit: Robust LLM Fingerprinting through Localized Knowledge Editing",
            link: "https://arxiv.org/abs/2508.02092",
            venue: "arXiv 2025.08-2025.10",
            bibtex: `@misc{wang2025fpeditrobustllmfingerprinting,
  title={FPEdit: Robust LLM Fingerprinting through Localized Parameter Editing}, 
  author={Shida Wang and Chaohu Liu and Yubo Wang and Linli Xu},
  year={2025},
  eprint={2508.02092},
  archivePrefix={arXiv},
  primaryClass={cs.CR},
  url={https://arxiv.org/abs/2508.02092}
}`,
          },
          {
            title: "From Injection to Defense: Constructing Edit-Based Fingerprints for Large Language Models",
            link: "https://arxiv.org/abs/2509.03122",
            venue: "arXiv 2025.09-2025.10",
            bibtex: `@misc{li2026constructioninjectioneditbasedfingerprints,
  title={From Construction to Injection: Edit-Based Fingerprints for Large Language Models}, 
  author={Yue Li and Xin Yi and Dongsheng Shi and Yongyi Cui and Gerard de Melo and Linlin Wang},
  year={2026},
  eprint={2509.03122},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2509.03122}
}`,
          },
          {
            title: "EditMark: Watermarking Large Language Models based on Model Editing",
            link: "https://arxiv.org/abs/2510.16367",
            venue: "arXiv 2025.10",
            bibtex: `@misc{li2025editmarkwatermarkinglargelanguagemodels,
  title={EditMark: Watermarking Large Language Models based on Model Editings}, 
  author={Shuai Li and Kejiang Chen and Jun Koamh and Jie Zhang and Qiyi Yao and Kai Zeng and Weiming Zhang and Nenghai Yu},
  year={2025},
  eprint={2510.16367},
  archivePrefix={arXiv},
  primaryClass={cs.CR},
  url={https://arxiv.org/abs/2510.16367}
}`,          
          },
          {
            title: "EditMF: Drawing an Invisible Fingerprint for Your Large Language Models",
            link: "https://arxiv.org/abs/2508.08836",
            venue: "arXiv 2025.08",
            bibtex: `@misc{wu2025editmfdrawinginvisiblefingerprint,
  title={EditMF: Drawing an Invisible Fingerprint for Your Large Language Models}, 
  author={Jiaxuan Wu and Yinghan Zhou and Wanli Peng and Yiming Xue and Juan Wen and Ping Zhong},
  year={2025},
  eprint={2508.08836},
  archivePrefix={arXiv},
  primaryClass={cs.CR},
  url={https://arxiv.org/abs/2508.08836}
}`,
          },
        ], // Knowledge Editing papers
      };

      document.addEventListener("DOMContentLoaded", () => {
        // Add papers to their respective containers
        Object.entries(papers).forEach(([category, paperList]) => {
          const container = document.getElementById(`${category}-papers`);
          if (container && paperList.length > 0) {
            paperList.forEach((paper) => {
              container.appendChild(createPaperReference(paper));
            });
          }
        });
      });
    </script>
  </body>
</html>
