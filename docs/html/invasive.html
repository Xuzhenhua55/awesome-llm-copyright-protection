<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
     <title>Invasive Fingerprinting - LLM Copyright Protection Research</title>
     <link rel="icon" type="image/svg+xml" href="../assets/logo.svg" />
     <link rel="stylesheet" href="../assets/style.css" />
    <link rel="stylesheet" href="../assets/nav.css" />
    <link rel="stylesheet" href="../assets/footer.css" />
    <link rel="stylesheet" href="../assets/paper-ref.css" />
    <link rel="stylesheet" href="../assets/layout.css" />
    <script>
      // Preload navigation content
      const cachedNav = localStorage.getItem("navContent");
      if (cachedNav) {
        document.addEventListener("DOMContentLoaded", () => {
          const navPlaceholder = document.getElementById("nav-placeholder");
          if (navPlaceholder) {
            navPlaceholder.innerHTML = cachedNav;
          }
        });
      }
    </script>
  </head>
  <body>
    <div id="nav-placeholder">
      <script>
        // Try to populate navigation immediately if available
        const navContent = localStorage.getItem("navContent");
        if (navContent) {
          document.write(navContent);
        }
      </script>
    </div>

    <div class="main-content">
      <div class="header-section">
        <h1>Invasive Fingerprinting</h1>
        <p class="intro-text">
          Invasive model fingerprinting techniques typically involve embedding
          information into the model's weights to construct fingerprint
          features. The purpose is to achieve model authentication and copyright
          protection. The general paradigm is to embed fingerprint information
          into the model and subsequently extract it from the model.
        </p>
      </div>

      <div class="section-card">
        <h2>Weight Watermark As Fingerprint</h2>
        <p>
          Embedding watermark information into model weights is a widely used
          fingerprinting technique, where the watermark serves as a traceable
          model fingerprint. By adjusting parameters during the training phase,
          fingerprint information can be embedded into weights, biases, or other
          model parameters. By comparing the parameter fingerprints extracted
          from a suspicious model with those in the owner's model, the owner can
          verify the model's identity.
        </p>
        <div id="weightWatermark-papers" class="paper-list"></div>
      </div>

      <div
        style="
          background: white;
          border-radius: 12px;
          padding: 2rem;
          margin: 2.5rem 0;
          box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
          border: 1px solid #e2e8f0;
          text-align: center;
        "
      >
        <img
          src="../assets/figures/invasive_fingerprint.png"
          alt="Invasive Fingerprinting Process"
          style="
            max-width: 60%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
          "
        />
        <p
          style="
            margin-top: 0.8rem;
            color: #666;
            font-style: italic;
            font-size: 0.95em;
            line-height: 1.4;
            margin-bottom: 0;
          "
        >
          <strong>Figure:</strong> Overview of invasive fingerprinting methods,
          illustrating weight watermarking and backdoor watermarking approaches
          for embedding fingerprint information into model parameters.
        </p>
      </div>

      <div class="section-card">
        <h2>Backdoor Watermark As Fingerprint</h2>
        <p>
          In practical scenarios, the model parameters and network architectures
          in commercial services are usually kept secret, so the above methods
          of embedding fingerprints into model parameters and network layers are
          often not feasible. Therefore, the fingerprinting technique based on
          backdoor watermark is more suitable for black-box environments and is
          more widely used in practical applications. In this scenario, the
          backdoor watermark, as a verifiable model fingerprint, is referred to
          as a backdoor fingerprint. The backdoor fingerprint mainly constructs
          special backdoor datasets and implants them into the model, enabling
          the backdoored model to trigger predefined backdoor responses and
          extract fingerprint information when encountering backdoor triggers
          that meet the trigger conditions.
        </p>
        <div id="backdoorWatermark-papers" class="paper-list"></div>
      </div>
    </div>

    <div id="footer-placeholder"></div>

    <script src="../assets/nav.js"></script>
    <script src="../assets/footer.js"></script>
    <script src="../assets/paper-ref.js"></script>
    <script>
      // Add paper references
      const papers = {
        weightWatermark: [
          {
            title:
              "EmMark: Robust watermarks for IP protection of embedded quantized large language models",
            link: "https://dl.acm.org/doi/abs/10.1145/3649329.3655674",
            venue: "DAC 2024",
            bibtex: `@inproceedings{zhang2024emmark,
  title={EmMark: Robust watermarks for IP protection of embedded quantized large language models},
  author={Zhang, Ruisi and Koushanfar, Farinaz},
  booktitle={Proceedings of the 61st ACM/IEEE Design Automation Conference},
  pages={1--6},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title:
              "Invariant-based Robust Weights Watermark for Large Language Models",
            link: "https://arxiv.org/abs/2507.08288",
            venue: "arXiv 2025",
            bibtex: `@article{guo2025invariant,
    title={Invariant‚ÄëBased Robust Weights Watermark for Large Language Models},
    author={Guo, Qingxiao and Zhu, Xinjie and Ma, Yilong and Jin, Hui and Wang, Yunhao and Zhang, Weifeng and Guo, Xiaobing},
    journal={arXiv preprint arXiv:2507.08288},
    year={2025}
  }`,
            surveyTag: "‚úçüèª",
          },
          {
            title:
              "Robust and Efficient Watermarking of Large Language Models Using Error Correction Codes",
            link: "https://petsymposium.org/popets/2025/popets-2025-0126.pdf",
            venue: "PoPETs 2025",
            bibtex: `@article{block2025robust,
    title={Robust and Efficient Watermarking of Large Language Models Using Error Correction Codes},
    author={Block, Adam and Sekhari, Ayush and Rakhlin, Alexander},
    journal={Proceedings on Privacy Enhancing Technologies (PoPETs) 2025},
    year={2025}
  }`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "Functional Invariants to Watermark Large Transformers",
            link: "https://arxiv.org/abs/2310.11446",
            venue: "ICASSP 2024",
            bibtex: `@inproceedings{fernandez2023functional,
  title={Functional Invariants to Watermark Large Transformers},
  author={Fernandez, Pierre and Couairon, Guillaume and Furon, Teddy and Douze, Matthijs},
  booktitle={ICASSP 2024},
  year={2023}
}`,
            surveyTag: "‚úçüèª",
          },
        ], // Weight Watermark papers
        backdoorWatermark: [
        {
            title: "NSmark: Null Space Based Black-box Watermarking Defense Framework for Language Models",
            link: "https://arxiv.org/abs/2410.13907",
            venue: "WMARK@ICLR2025",
            code: "https://github.com/dongdongzhaoUP/NSmark",
            bibtex: `@inproceedings{zhaonsmark,
  title={NSmark: Null Space Based Black-box Watermarking Defense Framework for Language Models},
  author={Zhao, Haodong and Hu, Jinming and Li, Peixuan and Li, Fangqi and Sha, Jinrui and Ju, Tianjie and Zhang, Zhuosheng and Liu, Gongshen and others},
  booktitle={The 1st Workshop on GenAI Watermarking},
  year={2025}
}`,
          },
          {
            title: "Instructional Fingerprinting of Large Language Models",
            link: "https://aclanthology.org/2024.naacl-long.180/",
            venue: "NAACL 2024",
            code: "https://cnut1648.github.io/Model-Fingerprint",
            bibtex: `@inproceedings{xu2024instructional,
  title={Instructional Fingerprinting of Large Language Models},
  author={Xu, Jiashu and Wang, Fei and Ma, Mingyu and Koh, Pang Wei and Xiao, Chaowei and Chen, Muhao},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={3277--3306},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "Scalable Fingerprinting of Large Language Models",
            link: "https://arxiv.org/abs/2502.07760",
            venue: "WMARK@ICLR2025",
            bibtex: `@inproceedings{zhang2025scalable,
  title={Scalable Fingerprinting of Large Language Models},
  author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
  booktitle={International Conference on Learning Representations},
  year={2025}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "ImF: Implicit Fingerprint for Large Language Models",
            link: "https://arxiv.org/abs/2503.21805",
            venue: "arXiv 2025",
            bibtex: `@article{zhang2025imf,
  title={ImF: Implicit Fingerprint for Large Language Models},
  author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2503.21805},
  year={2025}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title:
              "UTF Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification",
            link: "https://arxiv.org/abs/2410.12318",
            venue: "arXiv 2024",
            code: "https://anonymous.4open.science/r/fingerprint-2BCE/README.md",
            bibtex: `@article{cai2024utf,
  title={UTF: Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification},
  author={Cai, Jiacheng and Yu, Jiahao and Shao, Yangguang and Wu, Yuhang and Xing, Xinyu},
  journal={arXiv preprint arXiv:2410.12318},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title:
              "Hey, That\'s My Model!Introducing Chain & Hash,An LLM Fingerprinting Technique",
            link: "https://arxiv.org/abs/2407.10887",
            venue: "arXiv 2024",
            bibtex: `@article{russinovich2024hey,
  title={Hey, That\'s My Model! Introducing Chain \& Hash, An LLM Fingerprinting Technique},
  author={Russinovich, Mark and Salem, Ahmed},
  journal={arXiv preprint arXiv:2407.10887},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title:
              "MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models",
            link: "https://arxiv.org/abs/2410.08604",
            venue: "ACL 2025",
            bibtex: `@misc{yamabe2025mergeprintmergeresistantfingerprintsrobust,
      title={MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models}, 
      author={Shojiro Yamabe and Futa Waseda and Tsubasa Takahashi and Koki Wataoka},
      year={2025},
      eprint={2410.08604},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2410.08604}, 
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning",
            link: "https://arxiv.org/abs/2402.14883",
            venue: "arXiv 2024",
            bibtex: `@article{li2024double,
  title={Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning},
  author={Li, Shen and Yao, Liuyi and Gao, Jinyang and Zhang, Lan and Li, Yaliang},
  journal={arXiv preprint arXiv:2402.14883},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models",
            link: "https://ojs.aaai.org/index.php/AAAI/article/view/26750",
            venue: "AAAI 2023",
            bibtex: `@inproceedings{li2023plmmark,
  title={PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models},
  author={Li, Peixuan and Cheng, Pengzhou and Li, Fangqi and Du, Wei and Zhao, Haodong and Liu, Gongshen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence 2023},
  pages={14991--14999},
  year={2023}
}`,
            surveyTag: "‚úçüèª",
          },
        ], // Backdoor Watermark papers
      };

      document.addEventListener("DOMContentLoaded", () => {
        // Add papers to their respective containers
        Object.entries(papers).forEach(([category, paperList]) => {
          const container = document.getElementById(`${category}-papers`);
          if (container && paperList.length > 0) {
            paperList.forEach((paper) => {
              container.appendChild(createPaperReference(paper));
            });
          }
        });
      });
    </script>
  </body>
</html>
