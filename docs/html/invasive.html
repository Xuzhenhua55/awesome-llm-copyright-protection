<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
     <title>Invasive Fingerprinting - LLM Copyright Protection Research</title>
     <link rel="icon" type="image/svg+xml" href="../assets/logo.svg" />
     <link rel="stylesheet" href="../assets/style.css" />
    <link rel="stylesheet" href="../assets/nav.css" />
    <link rel="stylesheet" href="../assets/footer.css" />
    <link rel="stylesheet" href="../assets/paper-ref.css" />
    <link rel="stylesheet" href="../assets/layout.css" />
    <style>
      /* Unify paper entry widths across sections */
      .section-card {
        width: 100%;
        max-width: 100%;
        box-sizing: border-box;
      }

      .section-card p {
        margin-bottom: 1.5rem;
        min-height: 3rem; /* normalize description block height */
      }

      .paper-list {
        width: 100%;
        max-width: 100%;
        box-sizing: border-box;
        display: block;
      }

      .paper-reference {
        width: 100%;
        max-width: 100%;
        box-sizing: border-box;
        margin: 10px 0;
      }
    </style>
    <script>
      // Preload navigation content
      const cachedNav = localStorage.getItem("navContent");
      if (cachedNav) {
        document.addEventListener("DOMContentLoaded", () => {
          const navPlaceholder = document.getElementById("nav-placeholder");
          if (navPlaceholder) {
            navPlaceholder.innerHTML = cachedNav;
          }
        });
      }
    </script>
  </head>
  <body>
    <div id="nav-placeholder">
      <script>
        // Try to populate navigation immediately if available
        const navContent = localStorage.getItem("navContent");
        if (navContent) {
          document.write(navContent);
        }
      </script>
    </div>

    <div class="main-content">
      <div class="header-section">
        <h1>Invasive Fingerprinting</h1>
        <p class="intro-text">
          Invasive model fingerprinting techniques typically involve embedding
          information into the model's weights to construct fingerprint
          features. The purpose is to achieve model authentication and copyright
          protection. The general paradigm is to embed fingerprint information
          into the model and subsequently extract it from the model.
        </p>
      </div>

      <div class="section-card">
        <h2>Weight Watermark As Fingerprint</h2>
        <p>
          Embedding watermark information into model weights is a widely used
          fingerprinting technique, where the watermark serves as a traceable
          model fingerprint. By adjusting parameters during the training phase,
          fingerprint information can be embedded into weights, biases, or other
          model parameters. By comparing the parameter fingerprints extracted
          from a suspicious model with those in the owner's model, the owner can
          verify the model's identity.
        </p>
        <div id="weightWatermark-papers" class="paper-list"></div>
      </div>

      <div
        style="
          background: white;
          border-radius: 12px;
          padding: 2rem;
          margin: 2.5rem 0;
          box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
          border: 1px solid #e2e8f0;
          text-align: center;
        "
      >
        <img
          src="../assets/figures/invasive_fingerprint.png"
          alt="Invasive Fingerprinting Process"
          style="
            max-width: 60%;
            height: auto;
            border-radius: 8px;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
          "
        />
        <p
          style="
            margin-top: 0.8rem;
            color: #666;
            font-style: italic;
            font-size: 0.95em;
            line-height: 1.4;
            margin-bottom: 0;
          "
        >
          <strong>Figure:</strong> Overview of invasive fingerprinting methods,
          illustrating weight watermarking and backdoor watermarking approaches
          for embedding fingerprint information into model parameters.
        </p>
      </div>

      <div class="section-card">
        <h2>Backdoor Watermark As Fingerprint</h2>
        <p>
          In practical scenarios, the model parameters and network architectures
          in commercial services are usually kept secret, so the above methods
          of embedding fingerprints into model parameters and network layers are
          often not feasible. Therefore, the fingerprinting technique based on
          backdoor watermark is more suitable for black-box environments and is
          more widely used in practical applications. In this scenario, the
          backdoor watermark, as a verifiable model fingerprint, is referred to
          as a backdoor fingerprint. The backdoor fingerprint mainly constructs
          special backdoor datasets and implants them into the model, enabling
          the backdoored model to trigger predefined backdoor responses and
          extract fingerprint information when encountering backdoor triggers
          that meet the trigger conditions.
        </p>
        <div id="backdoorWatermark-papers" class="paper-list"></div>
        
        <h3>Knowledge Editing</h3>
        <p>
          Knowledge Editing provides a localized mechanism for embedding controllable fingerprint behaviors within backdoor-based frameworks. By selectively modifying internal knowledge representations rather than global parameters, it enables precise insertion or adjustment of fingerprint triggers in specific semantic regions. This approach preserves the model's overall performance while allowing the fingerprint to manifest as a verifiable micro-knowledge unit that can be activated under defined trigger conditions, offering a flexible and black-box‚Äìcompatible means of fingerprint implantation and verification.
        </p>
        <div id="knowledgeEditing-papers" class="paper-list"></div>
      </div>
    </div>

    <div id="footer-placeholder"></div>

    <script src="../assets/nav.js"></script>
    <script src="../assets/footer.js"></script>
    <script src="../assets/paper-ref.js"></script>
    <script>
      // Add paper references
      const papers = {
        weightWatermark: [
          {
            title: "Towards the Resistance of Neural Network Watermarking to Fine-tuning",
            link: "https://arxiv.org/abs/2505.01007",
            venue: "arXiv 2025.05",
            bibtex: `@article{yang2025resistance,
  title={Towards the Resistance of Neural Network Watermarking to Fine-tuning},
  author={Yang, Xiaofan and Zhao, Yuxin and Li, Sheng and Qian, Zhenxing and Zhang, Xinpeng},
  journal={arXiv preprint arXiv:2505.01007},
  year={2025}
}`
          },
          {
            title:
              "EmMark: Robust watermarks for IP protection of embedded quantized large language models",
            link: "https://dl.acm.org/doi/abs/10.1145/3649329.3655674",
            venue: "DAC 2024",
            bibtex: `@inproceedings{zhang2024emmark,
  title={EmMark: Robust watermarks for IP protection of embedded quantized large language models},
  author={Zhang, Ruisi and Koushanfar, Farinaz},
  booktitle={Proceedings of the 61st ACM/IEEE Design Automation Conference},
  pages={1--6},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title:
              "Invariant-based Robust Weights Watermark for Large Language Models",
            link: "https://arxiv.org/abs/2507.08288",
            venue: "arXiv 2025.07",
            bibtex: `@article{guo2025invariant,
    title={Invariant‚ÄëBased Robust Weights Watermark for Large Language Models},
    author={Guo, Qingxiao and Zhu, Xinjie and Ma, Yilong and Jin, Hui and Wang, Yunhao and Zhang, Weifeng and Guo, Xiaobing},
    journal={arXiv preprint arXiv:2507.08288},
    year={2025}
  }`,
            surveyTag: "‚úçüèª",
          },
          {
            title:
              "Robust and Efficient Watermarking of Large Language Models Using Error Correction Codes",
            link: "https://petsymposium.org/popets/2025/popets-2025-0126.pdf",
            venue: "PoPETs 2025",
            bibtex: `@article{block2025robust,
    title={Robust and Efficient Watermarking of Large Language Models Using Error Correction Codes},
    author={Block, Adam and Sekhari, Ayush and Rakhlin, Alexander},
    journal={Proceedings on Privacy Enhancing Technologies (PoPETs) 2025},
    year={2025}
  }`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "Functional Invariants to Watermark Large Transformers",
            link: "https://arxiv.org/abs/2310.11446",
            venue: "ICASSP 2024",
            bibtex: `@inproceedings{fernandez2023functional,
  title={Functional Invariants to Watermark Large Transformers},
  author={Fernandez, Pierre and Couairon, Guillaume and Furon, Teddy and Douze, Matthijs},
  booktitle={ICASSP 2024},
  year={2023}
}`,
            surveyTag: "‚úçüèª",
          },
        ], // Weight Watermark papers
        backdoorWatermark: [
          {
            title: "InSty: A Robust Multi-Level Cross-Granularity Fingerprint Embedding Algorithm for Multi-Turn Dialogue in Large Language Models",
            link: "https://www.sciengine.com/SSI/doi/10.1360/SSI-2025-0022",
            venue: "SCIS 2025",
            bibtex: `@article{li2025insty,
  title={InSty: A Robust Multi-Level Cross-Granularity Fingerprint Embedding Algorithm for Multi-Turn Dialogue in Large Language Models},
  author={Li, Rui and Zhang, Yuxiang and Xu, Shicheng and Qian, Zhenxing and Zhang, Xinpeng},
  journal={Science China Information Sciences},
  year={2025},
  doi={10.1360/SSI-2025-0022}
}`
          },
          {
            title: "CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor",
            link: "https://arxiv.org/abs/2509.09703",
            venue: "EMNLP 2025",
            bibtex: `@article{ren2025ctcc,
  title={CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor},
  author={Ren, Zhenzhen and Li, Guobiao and Li, Sheng and Qian, Zhenxing and Zhang, Xinpeng},
  journal={arXiv preprint arXiv:2509.09703},
  year={2025}
}`
          },
          {
            title: "Beyond Dataset Watermarking: Model-Level Copyright Protection for Code Summarization Models",
            link: "https://dl.acm.org/doi/10.1145/3696410.3714641",
            venue: "ACM FSE 2025",
            bibtex: `@inproceedings{wang2025beyond,
  title={Beyond Dataset Watermarking: Model-Level Copyright Protection for Code Summarization Models},
  author={Wang, Qiang and Zhao, Xiaoqing and Wang, Xin and Liu, Hongyu},
  booktitle={Proceedings of the 33rd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  pages={1--12},
  year={2025},
  organization={ACM}
}`
          },
          {
            title: "TIBW: Task-Independent Backdoor Watermarking with Fine-Tuning Resilience for Pre-Trained Language Models",
            link: "https://www.mdpi.com/2227-7390/13/2/272",
            venue: "MDPI 2025",
            bibtex: `@article{zhao2025tibw,
  title={TIBW: Task-Independent Backdoor Watermarking with Fine-Tuning Resilience for Pre-Trained Language Models},
  author={Zhao, Meng and Zhu, Yujie and Wang, Yuyang and Li, Rui and Zhang, Qian},
  journal={Mathematics},
  volume={13},
  number={2},
  pages={272},
  year={2025},
  publisher={MDPI}
}`
          },
        {
            title: "NSmark: Null Space Based Black-box Watermarking Defense Framework for Language Models",
            link: "https://arxiv.org/abs/2410.13907",
            venue: "WMARK@ICLR2025",
            code: "https://github.com/dongdongzhaoUP/NSmark",
            bibtex: `@inproceedings{zhaonsmark,
  title={NSmark: Null Space Based Black-box Watermarking Defense Framework for Language Models},
  author={Zhao, Haodong and Hu, Jinming and Li, Peixuan and Li, Fangqi and Sha, Jinrui and Ju, Tianjie and Zhang, Zhuosheng and Liu, Gongshen and others},
  booktitle={The 1st Workshop on GenAI Watermarking},
  year={2025}
}`,
          },
          {
            title: "Instructional Fingerprinting of Large Language Models",
            link: "https://aclanthology.org/2024.naacl-long.180/",
            venue: "NAACL 2024",
            code: "https://cnut1648.github.io/Model-Fingerprint",
            bibtex: `@inproceedings{xu2024instructional,
  title={Instructional Fingerprinting of Large Language Models},
  author={Xu, Jiashu and Wang, Fei and Ma, Mingyu and Koh, Pang Wei and Xiao, Chaowei and Chen, Muhao},
  booktitle={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
  pages={3277--3306},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "Scalable Fingerprinting of Large Language Models",
            link: "https://arxiv.org/abs/2502.07760",
            venue: "WMARK@ICLR2025",
            bibtex: `@inproceedings{zhang2025scalable,
  title={Scalable Fingerprinting of Large Language Models},
  author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
  booktitle={International Conference on Learning Representations},
  year={2025}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "ImF: Implicit Fingerprint for Large Language Models",
            link: "https://arxiv.org/abs/2503.21805",
            venue: "arXiv 2025.03-2025.08",
            bibtex: `@article{zhang2025imf,
  title={ImF: Implicit Fingerprint for Large Language Models},
  author={Zhang, Jie and Liu, Dongrui and Qian, Chen and Zhang, Linfeng and Liu, Yong and Qiao, Yu and Shao, Jing},
  journal={arXiv preprint arXiv:2503.21805},
  year={2025}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title:
              "UTF Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification",
            link: "https://aclanthology.org/2025.llmsec-1.1.pdf",
            venue: "ACL 2025",
            code: "https://anonymous.4open.science/r/fingerprint-2BCE/README.md",
            bibtex: `@article{cai2024utf,
  title={UTF: Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification},
  author={Cai, Jiacheng and Yu, Jiahao and Shao, Yangguang and Wu, Yuhang and Xing, Xinyu},
  journal={arXiv preprint arXiv:2410.12318},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title:
              "Hey, That\'s My Model!Introducing Chain & Hash,An LLM Fingerprinting Technique",
            link: "https://arxiv.org/abs/2407.10887",
            venue: "arXiv 2024.07-2025.06",
            bibtex: `@article{russinovich2024hey,
  title={Hey, That\'s My Model! Introducing Chain \& Hash, An LLM Fingerprinting Technique},
  author={Russinovich, Mark and Salem, Ahmed},
  journal={arXiv preprint arXiv:2407.10887},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title:
              "MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models",
            link: "https://arxiv.org/abs/2410.08604",
            venue: "ACL 2025",
            bibtex: `@misc{yamabe2025mergeprintmergeresistantfingerprintsrobust,
      title={MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models}, 
      author={Shojiro Yamabe and Futa Waseda and Tsubasa Takahashi and Koki Wataoka},
      year={2025},
      eprint={2410.08604},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2410.08604}, 
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning",
            link: "https://arxiv.org/abs/2402.14883",
            venue: "arXiv 2024.02-2024.06",
            bibtex: `@article{li2024double,
  title={Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning},
  author={Li, Shen and Yao, Liuyi and Gao, Jinyang and Zhang, Lan and Li, Yaliang},
  journal={arXiv preprint arXiv:2402.14883},
  year={2024}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models",
            link: "https://ojs.aaai.org/index.php/AAAI/article/view/26750",
            venue: "AAAI 2023",
            bibtex: `@inproceedings{li2023plmmark,
  title={PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models},
  author={Li, Peixuan and Cheng, Pengzhou and Li, Fangqi and Du, Wei and Zhao, Haodong and Liu, Gongshen},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence 2023},
  pages={14991--14999},
  year={2023}
}`,
            surveyTag: "‚úçüèª",
          },
          {
            title: "CLMTracing: Black-box User-level Watermarking for Code Language Model Tracing",
            link: "https://arxiv.org/abs/2509.13982",
            venue: "arXiv 2025.09",
            bibtex: `@article{chen2025clmtracing,
  title={CLMTracing: Black-box User-level Watermarking for Code Language Model Tracing},
  author={Chen, Zhen and Zhang, Yuxuan and Li, Mingjie and Fang, Xiaojun and Lin, Jia and Zhang, Zhenyu and Zhang, Tao and Sun, Lichao and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2509.13982},
  year={2025}
}`
          },
          {
            title: "Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution",
            link: "https://www.ndss-symposium.org/ndss-paper/explanation-as-a-watermark-towards-harmless-and-multi-bit-model-ownership-verification-via-watermarking-feature-attribution/",
            venue: "NDSS 2025",
            bibtex: `@article{zhang2024explanation,
  title={Explanation as a Watermark: Towards Harmless and Multi-bit Model Ownership Verification via Watermarking Feature Attribution},
  author={Zhang, Yifeng and Sun, Yifan and Lu, Yunchao and Zhang, Xiangyu and Wu, Baoyuan},
  journal={arXiv preprint arXiv:2405.04825},
  year={2024}
}`
          },
          {
            title: "Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge",
            link: "https://aclanthology.org/2025.findings-acl.736/",
            venue: "Findings of ACL 2025",
            bibtex: `@article{liu2025robust,
  title={Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge},
  author={Liu, Runlin and Zhao, Yuxin and Chen, Jialuo and Ma, Xingjun},
  journal={arXiv preprint arXiv:2503.04036},
  year={2025}
}`
          },
        ], // Backdoor Watermark papers
        knowledgeEditing: [
          {
            title: "PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement",
            link: "https://arxiv.org/abs/2509.00918",
            venue: "EMNLP 2025",
            bibtex: `@article{liu2025pree,
  title={PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement},
  author={Liu, Sihan and Wang, Yuexiang and Zhao, Meng and Zhu, Yunlong and Zhang, Shuyang and Chen, Weiyu and Huang, Lei and Chen, Kai},
  journal={arXiv preprint arXiv:2509.00918},
  year={2025}
}`
          },
          {
            title: "FPEdit: Robust LLM Fingerprinting through Localized Knowledge Editing",
            link: "https://arxiv.org/abs/2508.02092",
            venue: "arXiv 2025.08-2025.10",
            bibtex: `@article{zhang2025fpedit,
  title={FPEdit: Robust LLM Fingerprinting through Localized Knowledge Editing},
  author={Zhang, Bowen and Xu, Shuzhou and Wu, Ming and Yang, Tianyu and Lin, Wei and Ren, Kui},
  journal={arXiv preprint arXiv:2508.02092},
  year={2025}
}`,
          },
          {
            title: "From Injection to Defense: Constructing Edit-Based Fingerprints for Large Language Models",
            link: "https://arxiv.org/abs/2509.03122",
            venue: "arXiv 2025.09-2025.10",
            bibtex: `@article{xu2025from,
  title={From Injection to Defense: Constructing Edit-Based Fingerprints for Large Language Models},
  author={Xu, Yujian and Chen, Shicheng and Zhu, Yixiao and Ren, Weijie and Li, Sheng and Qian, Zhenxing and Zhang, Xinpeng},
  journal={arXiv preprint arXiv:2509.03122},
  year={2025}
}`,
          },
          {
            title: "EditMF: Drawing an Invisible Fingerprint for Your Large Language Models",
            link: "https://arxiv.org/abs/2508.08836",
            venue: "arXiv 2025.08",
            bibtex: `@article{chen2025editmf,
  title={EditMF: Drawing an Invisible Fingerprint for Your Large Language Models},
  author={Chen, Zhiyu and Yang, Haotian and Liu, Jiajun and Zhang, Jun and Lin, Hanyu and Chen, Kai and Wang, Haonan and Yang, Ziqi},
  journal={arXiv preprint arXiv:2508.08836},
  year={2025}
}`,
          },
        ], // Knowledge Editing papers
      };

      document.addEventListener("DOMContentLoaded", () => {
        // Add papers to their respective containers
        Object.entries(papers).forEach(([category, paperList]) => {
          const container = document.getElementById(`${category}-papers`);
          if (container && paperList.length > 0) {
            paperList.forEach((paper) => {
              container.appendChild(createPaperReference(paper));
            });
          }
        });
      });
    </script>
  </body>
</html>
